{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Packages\n",
    "import time, cv2, sys, os, torch, re\n",
    "from threading import Thread\n",
    "from djitellopy import Tello\n",
    "import openai\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import random as r\n",
    "from transformers import ViltProcessor, ViltForQuestionAnswering\n",
    "\n",
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Configure Packages\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path+\"/prompts/\")\n",
    "    \n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path+\"/Scripts/\")\n",
    "    \n",
    "# Import Local Packages\n",
    "from vqa_question.v1 import prompt_template as vqa_prompt_template\n",
    "from drone_explore_prompt import prompt_template as explore_template\n",
    "from drone_next_action.v1 import prompt_template as drone_prompt_template\n",
    "\n",
    "from data_collection_utils import take_individual_picture, stream_video, stream_frames, record_streamed_frames\n",
    "\n",
    "print(\"Imported all modules\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize YOLOv8\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolov8n.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coords(obj_name, img_url, verbose=False):\n",
    "    \"\"\"\n",
    "    Function to obtain the bounding box coordinates of an object in an image.\n",
    "\n",
    "    Args:\n",
    "        obj_name (Any Valid YOLO Class): The object of interest.\n",
    "        img_url (str): Location of the image to perform analysis on.\n",
    "        verbose (bool, optional): Whether or not to print out the names of all objects detected within the images. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        result_tuple (tuple(int), tuple(int)): Bounding box coordinates.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    pred = model(img_url)\n",
    "    \n",
    "    if verbose:\n",
    "        print(pred)\n",
    "\n",
    "    # get bouning box coordinates for object\n",
    "    classes = pred[0].boxes.cls\n",
    "\n",
    "    idx_to_name = pred[0].names\n",
    "\n",
    "    names = [idx_to_name[int(i)] for i in classes]\n",
    "    if obj_name not in names:\n",
    "        if verbose:\n",
    "            print(names)\n",
    "        print(time.time() - start_time, 'seconds elapsed')\n",
    "        return None, None\n",
    "    \n",
    "    idx_obj = names.index(obj_name)\n",
    "    coords = pred[0].boxes.xyxy[idx_obj]\n",
    "    if verbose:\n",
    "        print(names)\n",
    "    print(time.time() - start_time, 'seconds elapsed')\n",
    "    \n",
    "    result_tuple = (int(coords[0].item()), int(coords[1].item())), (int(coords[2].item()), int(coords[3].item()))\n",
    "    return result_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_box(img, top_left, bottom_right):\n",
    "    \"\"\"\n",
    "    Draw a bounding box on a given image.\n",
    "\n",
    "    Args:\n",
    "        img (any valid image object): Original image.\n",
    "        top_left (tuple): Top left coordinates of the bounding box.\n",
    "        bottom_right (tuple): Bottom right coordinates of the bounding box.\n",
    "    \"\"\"\n",
    "    rect = cv2.rectangle(img, top_left, bottom_right, (0, 255, 0), 2)\n",
    "    cv2.imshow(\"Video Feed\", rect)\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Drone\n",
    "drone = Tello()\n",
    "drone.connect()\n",
    "\n",
    "# Check Battery Levels\n",
    "drone.get_battery()\n",
    "\n",
    "# Initialize variables for bounding box coordinates\n",
    "top_left, bottom_right = None, None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt(prompt, stop_tokens = None):\n",
    "    \"\"\"\n",
    "    Return an LLM Response to a Prompt.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): Original LLM Prompt\n",
    "        stop_tokens (list, optional): List of stop tokens for the LLM. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",\n",
    "        prompt=prompt,\n",
    "        temperature=0.5,\n",
    "        max_tokens=1000,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        best_of=1,\n",
    "        stop=stop_tokens,\n",
    "    )\n",
    "    return response.choices[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Prompt Template for Simple Drone Flight\n",
    "prompt_text=\"\"\"You are writing code to control a drone.\n",
    "Here is a list of commands:\n",
    "    drone.move_left(X)  - move the drone left by X centimeters, where X is between 20 and 500\n",
    "    drone.move_right(X) - move the drone right by X centimeters, where X is between 20 and 500\n",
    "    drone.move_forward(X) - move the drone forward by X centimeters, where X is between 20 and 500\n",
    "    drone.move_back(X) - move the drone back by X centimeters, where X is between 20 and 500\n",
    "    drone.takeoff() - lift off the drone\n",
    "    drone.land() - land the drone\n",
    "    drone.rotate_clockwise(X) - rotate the drone clockwise by X degrees, where X is between 1 and 360\n",
    "    drone.rotate_counter_clockwise(X) - rotate the drone counter-clockwise by X degrees, where X is between 1 and 360\n",
    "\n",
    "Write the code needed for an algorithm to $objective\n",
    "You need to start by taking off with the drone.takeoff() command and end by landing with the drone.land() command.\n",
    "Please insert helpful print statements to document the progress towards the objective.\n",
    "\n",
    "Code:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated Prompt Template which incorporates object detection results to modify trajectory\n",
    "prompt_image=\"\"\"You are writing code to control a drone.\n",
    "Here is a list of commands:\n",
    "    drone.move_left(X)  - move the drone left by X centimeters, where X is between 20 and 50\n",
    "    drone.move_right(X) - move the drone right by X centimeters, where X is between 20 and 50\n",
    "    drone.move_forward(X) - move the drone forward by X centimeters, where X is between 20 and 50\n",
    "    drone.move_back(X) - move the drone back by X centimeters, where X is between 20 and 50\n",
    "    drone.takeoff() - lift off the drone\n",
    "    drone.land() - land the drone\n",
    "    drone.rotate_clockwise(X) - rotate the drone clockwise by X degrees, where X is between 1 and 360\n",
    "    drone.rotate_counter_clockwise(X) - rotate the drone counter-clockwise by X degrees, where X is between 1 and 360\n",
    "    object_detect(X) - takes in the name of an object X, and returns True or False depending on whether the object is in the frame. valid values for X are [bottle, person, chair]\n",
    "\n",
    "Write the code needed for an algorithm to $objective\n",
    "You need to start by taking off with the drone.takeoff() command and end by landing with the drone.land() command.\n",
    "Please insert helpful print statements to document the progress towards the objective.\n",
    "\n",
    "Code:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def object_detect(obj: str) -> bool:\n",
    "    \"\"\"\n",
    "    Detects an object in the frame and returns True or False depending on whether the object is in the frame. If true, the function draws a bounding box around the object of interest.\n",
    "\n",
    "    Args:\n",
    "        obj (str): The name of the object of interest.\n",
    "\n",
    "    Returns:\n",
    "        bool: Whether or not the object of interest is within the image frame.\n",
    "    \"\"\"\n",
    "    # Initialize drone stream\n",
    "    drone.streamon()\n",
    "    time.sleep(10)\n",
    "    \n",
    "    # Obtain live image from drone\n",
    "    img = drone.get_frame_read().frame\n",
    "    img = cv2.resize(img, (360, 240))\n",
    "\n",
    "    # Obtain bounding box coordinates for object and display image + bounding box coordinates\n",
    "    top_left, bottom_right = get_coords(obj, img)\n",
    "    print('coords', top_left, bottom_right)\n",
    "    cv2.imshow(\"image\", img)\n",
    "    cv2.waitKey(1)\n",
    "    \n",
    "    # Plot bounding box if the object is in the frame\n",
    "    if top_left is not None:\n",
    "        print(\"Bottle Found!\")\n",
    "        plot_box(img, top_left=top_left, bottom_right=bottom_right)\n",
    "        time.sleep(10)\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test object detection on a bottle in a sample frame\n",
    "object_detect(\"bottle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt the LLM with an objective and print out the resulting LLM-generated action code\n",
    "code_str = prompt(prompt_image.replace(\"$objective\", \"find the bottle\"))\n",
    "print(code_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the LLM-generated action code\n",
    "exec(code_str)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flight Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drone.takeoff() # launch drone\n",
    "\n",
    "drone.get_battery() # obtain battery levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "def find_center_coord_for_frame_size(size=(360, 240)):\n",
    "    \"\"\"\n",
    "    Find the center coordinates for a frame of a given size.\n",
    "\n",
    "    Args:\n",
    "        size (tuple, optional): Image Frame Size. Defaults to (360, 240).\n",
    "\n",
    "    Returns:\n",
    "        tuple(int): X and Y coordinates of the center.\n",
    "    \"\"\"\n",
    "    return (size[0]//2, size[1]//2)\n",
    "\n",
    "\n",
    "def find_center(top_l: tuple, bottom_r: tuple) -> tuple:\n",
    "    \"\"\"\n",
    "    Find the center coordinates of a bounding box, given the top left and bottom right coordinates\n",
    "\n",
    "    Args:\n",
    "        top_l (tuple): Top left coordinates of the bounding box.\n",
    "        bottom_r (tuple): Bottom right coordinates of the bounding box.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Coordinates of the center of the bounding box.\n",
    "    \"\"\"\n",
    "    top_w, top_h = top_l\n",
    "    bottom_w, bottom_h = bottom_r\n",
    "    center_x = ((bottom_w - top_w) // 2) + top_w\n",
    "    center_y = ((top_h - bottom_h) // 2) + bottom_h\n",
    "\n",
    "    return (center_x, center_y)\n",
    "\n",
    "\n",
    "def get_bbox_width_height(top_l: tuple, bottom_r: tuple) -> tuple:\n",
    "    \"\"\"\n",
    "    Find the width and height of a bounding box given the top left and bottom right coordinates.\n",
    "\n",
    "    Args:\n",
    "        top_l (_type_): Top left coordinates of the bounding box.\n",
    "        bottom_r (_type_): Bottom right coordinates of the bounding box.\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    top_w, top_h = top_l\n",
    "    bottom_w, bottom_h = bottom_r\n",
    "    return (bottom_w - top_w, top_h - bottom_h)\n",
    "\n",
    "\n",
    "def reorient(frame_center: tuple, bbox_center: tuple) -> None:\n",
    "    \"\"\"\n",
    "    Function to reorient the drone reference frame to be centered at the center of the bounding box by moving the drone.\n",
    "\n",
    "    Args:\n",
    "        frame_center (tuple): Center of the drone's image frame.\n",
    "        bbox_center (tuple): Center of the bounding box of the object of interest.\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    frame_x, frame_y = frame_center\n",
    "    bbox_x, bbox_y = bbox_center\n",
    "\n",
    "    if bbox_x > frame_x:\n",
    "        print(\"Move Right\")\n",
    "        move = (bbox_x - frame_x)\n",
    "        print(move)\n",
    "        drone.move_right(move)\n",
    "        \n",
    "    elif bbox_x < frame_x:\n",
    "        print(\"Move Left\")\n",
    "        move = (frame_x - bbox_x)\n",
    "        print(move)\n",
    "        drone.move_left(move)\n",
    "\n",
    "    if bbox_y > frame_y:\n",
    "        print(\"Move Down\")\n",
    "        move = (bbox_y - frame_y)\n",
    "        print(move)\n",
    "        drone.move_down(move)\n",
    "\n",
    "    elif bbox_y < frame_y:\n",
    "        print(\"Move Up\")\n",
    "        move = (frame_y - bbox_y)\n",
    "        print(move)\n",
    "        drone.move_up(move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exploit(top_left, bottom_right):\n",
    "    \"\"\"\n",
    "    Once a drone has locked on to an object or task of interest, this function is called to execute the prompted task. Currently, supported tasks include searching for an object and moving towards it.\n",
    "\n",
    "    Args:\n",
    "        top_left (tuple): Top left coordinates of the bounding box of the object of interest.\n",
    "        bottom_right (tuple): Bottom right coordinates of the bounding box of the object of interest.\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Align drone with object\n",
    "    frame_center = find_center_coord_for_frame_size((360, 240))\n",
    "    print('frame center', frame_center)\n",
    "    bbox_center = find_center(top_left, bottom_right)\n",
    "    print('box center', bbox_center)\n",
    "    reorient(frame_center, bbox_center)\n",
    "\n",
    "    # Go to object\n",
    "    width, height = get_bbox_width_height(top_left, bottom_right)\n",
    "    while width < 360 * 0.8 and height < 240 * 0.8:\n",
    "        print('move forward')\n",
    "        # drone.move_forward(10)\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def track():\n",
    "    \"\"\"\n",
    "    Exploration-Exploitation Function: If the object of interest is detected after prompting, the drone takes off and flies towards it.\n",
    "    \"\"\"\n",
    "    drone.streamon()\n",
    "    time.sleep(10)\n",
    "    while True:\n",
    "        img = drone.get_frame_read().frame\n",
    "        img = cv2.resize(img, (360, 240))\n",
    "        top_left, bottom_right = get_coords(\"bottle\", img)\n",
    "        cv2.imshow(\"image\", img)\n",
    "        cv2.waitKey(1)\n",
    "        if top_left is not None:\n",
    "            print(\"Bottle Found!\")\n",
    "            plot_box(img, top_left=top_left, bottom_right=bottom_right)\n",
    "            time.sleep(1)\n",
    "            drone.takeoff()\n",
    "            exploit(top_left=top_left, bottom_right=bottom_right)\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test exploration-exploitation\n",
    "if 0: # Tracking thread\n",
    "    trk = Thread(target=track)\n",
    "    trk.start()\n",
    "if 1:\n",
    "    track() # track objects in observation space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Legacy Functions (1st Implementation)\n",
    "def find_corners(upper_left: tuple, length: float, width: float) -> list:\n",
    "    \"\"\"\n",
    "    Find the 4 corners of a bounding box, given the upper left corner, length, and width.\n",
    "\n",
    "    Args:\n",
    "        upper_left (tuple): Upper left coordinates of the bounding box.\n",
    "        length (float): Length of the bounding box\n",
    "        width (float): Width of the bounding box\n",
    "\n",
    "    Returns:\n",
    "        corners (list): A list containing the coordinates of the 4 corners of the bounding box.\n",
    "    \"\"\"\n",
    "    corners = []\n",
    "    \n",
    "    upper_right = (upper_left[0] + length, upper_left[1])\n",
    "    lower_left =  (upper_left[0], upper_left[1] + width)\n",
    "    lower_right = (upper_left[0] + length, upper_left[1] + width)\n",
    "    \n",
    "    corners.append(upper_left)\n",
    "    corners.append(upper_right)\n",
    "    corners.append(lower_left)\n",
    "    corners.append(lower_right)\n",
    "    \n",
    "    return corners\n",
    "    \n",
    "\n",
    "def find_center(corners: list) -> tuple:\n",
    "    \"\"\"\n",
    "    Find the center coordinates of a bounding box, given the 4 corners of the bounding box.\n",
    "\n",
    "    Args:\n",
    "        corners (list): A list containing the coordinates of the 4 corners of the bounding box.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: Coordinates of the center of the bounding box.\n",
    "    \"\"\"\n",
    "    upper_left, upper_right, lower_left, lower_right = corners\n",
    "    \n",
    "    # create diagonal using upper left and lower right\n",
    "    center_x = (upper_left[0] + upper_right[0]) / 2\n",
    "    center_y = (upper_left[1] + lower_right[1]) / 2\n",
    "    \n",
    "    return(center_x, center_y)\n",
    "\n",
    "\n",
    "def compact_exploit(drone, bbox): # prompt_template = explore_template):\n",
    "    \"\"\"\n",
    "    Legacy compact implementation of the Exploit Function: Given the bounding box of a target of interest, execute two transformations to move closer to the object\n",
    "\n",
    "    Args:\n",
    "        drone: Tello (djiteleopy) object that specifies actions to be taken on a DJI Tello drone over WiFi and offers data streaming capabilities.\n",
    "        bbox (list): A list containing the 4 corners of a bounding box.\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Translate the object to the center\n",
    "    bounding_box_center = find_center(bbox)\n",
    "    current_image = drone.get_frame_read().frame\n",
    "    height, width, channel = current_image.shape\n",
    "    frame_center = (width / 2, height / 2)\n",
    "    \n",
    "    delta_y = frame_center[1] - bounding_box_center[1]\n",
    "    delta_x = frame_center[0] - bounding_box_center[0]\n",
    "    \n",
    "    if delta_y < 0:\n",
    "        drone.move_up(abs(delta_y))\n",
    "    else:\n",
    "        drone.move_down(abs(delta_y))\n",
    "    \n",
    "    if delta_x < 0:\n",
    "        drone.move_left(abs(delta_x))\n",
    "    else:\n",
    "        drone.move_right(abs(delta_x))\n",
    "    \n",
    "    # Zoom In (move towards the object)\n",
    "    bbox_length = bbox[1][0] - bbox[0][0]\n",
    "    bbox_width = bbox[1][1] - bbox[0][1]\n",
    "    \n",
    "    while bbox_width <= 100 or bbox_length <= 100:\n",
    "        drone.move_forward(10)\n",
    "    \n",
    "    # Terminate\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Pre-Trained VQA Model\n",
    "processor = ViltProcessor.from_pretrained(\"dandelin/vilt-b32-finetuned-vqa\")\n",
    "model = ViltForQuestionAnswering.from_pretrained(\"dandelin/vilt-b32-finetuned-vqa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the Drone\n",
    "objective = \"Find the person who is wearing a blue cap\" # initialize LLM objective prompt\n",
    "\n",
    "drone.connect() # Establish network connection\n",
    "\n",
    "take_individual_picture(drone) # take an individual picture to test imaging capabilities\n",
    "\n",
    "# Begin a thread and stream video frame by frame\n",
    "stream = Thread(target=stream_frames, args=(drone, False))\n",
    "stream.start()\n",
    "\n",
    "# Enable drone streaming and launch\n",
    "drone.streamon()\n",
    "drone.takeoff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_the_environment(drone, question):\n",
    "    \"\"\"\n",
    "    Given any image frame streamed from the drone, this function uses VQA to identify objects of interest specified by a prompt question.\n",
    "\n",
    "    Args:\n",
    "        drone: Tello (djiteleopy) object that specifies actions to be taken on a DJI Tello drone over WiFi and offers data streaming capabilities.\n",
    "        question (str): LLM objective prompt - high level task that is to be completed.\n",
    "\n",
    "    Returns:\n",
    "        str: Label of the object of interest specified by the question in the image\n",
    "    \"\"\"\n",
    "    image = drone.get_frame_read().frame\n",
    "    encoding = processor(image, question, return_tensors=\"pt\")\n",
    "    outputs = model(**encoding)\n",
    "    logits = outputs.logits\n",
    "    idx = torch.sigmoid(logits).argmax(-1).item()\n",
    "    return str(model.config.id2label[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_action_prompt(prompt_template, objective, environment_context, previous_commands, previous_context, vqa_questions):\n",
    "    \"\"\"\n",
    "    Generate a complete action prompt for the LLM given an objective, environment context, previous commands, previous context, and VQA questions.\n",
    "\n",
    "    Args:\n",
    "        prompt_template (str): LLM Prompt Template.\n",
    "        objective (str): The objective that the drone should complete.\n",
    "        environment_context (str): Environmental Context.\n",
    "        previous_commands (str): Previous commands given to the drone, converted into string form such that it can be added to the prompt.\n",
    "        previous_context (str): Previous environemal context understood by the drone.\n",
    "        vqa_questions (str): Questions for Visual Question-Answering.\n",
    "\n",
    "    Returns:\n",
    "        tuple(str, list): Prompt text and list containing stop tokens\n",
    "    \"\"\"\n",
    "    prompt = prompt_template.replace(\"$objective\", objective)\n",
    "    prompt = prompt.replace(\"$context\", environment_context)\n",
    "    prompt = prompt.replace(\"$previous_commands\", previous_commands)\n",
    "    prompt = prompt.replace(\"$previous_context\", previous_context)\n",
    "    prompt = prompt.replace(\"$vqa_questions\", vqa_questions)\n",
    "    return prompt, [\"\\n\"] # prompt and stop token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt(prompt, stop_tokens):\n",
    "    \"\"\"\n",
    "    Pass a prompt through an LLM model and return the output.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): Prompt to be passed through the LLM model.\n",
    "        stop_tokens (list): List of stop tokens for the LLM to parse through.\n",
    "\n",
    "    Returns:\n",
    "        str: LLM Prompt Response\n",
    "    \"\"\"\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",\n",
    "        prompt=prompt,\n",
    "        temperature=0.5,\n",
    "        max_tokens=1000,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        best_of=10,\n",
    "        stop=stop_tokens,\n",
    "    )\n",
    "    return response.choices[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vqa_questions(vqa_prompt_template, objective):\n",
    "    \"\"\"\n",
    "    Generate questions for VQA automatically given a prompt template and a user-specified objective.\n",
    "\n",
    "    Args:\n",
    "        vqa_prompt_template (str): Prompt template for VQA questions.\n",
    "        objective (str): User-specified objective that the drone is tasked to complete.\n",
    "\n",
    "    Returns:\n",
    "        matches (list): A list of questions that are used to query the VQA model.\n",
    "    \"\"\"\n",
    "    prompt_text = vqa_prompt_template.replace(\"$objective\", objective)\n",
    "    result = prompt(prompt_text, [\"&&&&&&\"])\n",
    "    matches = re.findall(r'@(.+?)@', result)\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate VQA Questions: test\n",
    "get_vqa_questions(vqa_prompt_template, objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore(drone, use_gpt=False, prompt_template=explore_template):\n",
    "    \"\"\"\n",
    "    Explore Function: Survey the room via a random though comprehensive flight path to find objects of interest as specified by the prompt.\n",
    "\n",
    "    Args:\n",
    "        drone: Tello (djiteleopy) object that specifies actions to be taken on a DJI Tello drone over WiFi and offers data streaming capabilities.\n",
    "        use_gpt (bool, optional): Whether or not to use a GPT-type LLM to parse through the prompt. Defaults to False.\n",
    "        prompt_template (str, optional): Prompt template for the specified objective. Defaults to explore_template.\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Generate Prompt Response\n",
    "    if use_gpt:\n",
    "       prompt(prompt_template)\n",
    "    else:\n",
    "        # randomly generate a number between 45 and 180\n",
    "        random_angle = r.randint(45, 180)\n",
    "        \n",
    "        # randomly generate a number between 5 and 20\n",
    "        random_distance = r.randint(5, 20)\n",
    "        action_space = [\n",
    "            (drone.move_left, random_distance),\n",
    "            (drone.move_right, random_distance),\n",
    "            (drone.rotate_clockwise, random_angle),\n",
    "            (drone.rotate_counter_clockwise, random_angle),\n",
    "            (drone.move_forward, random_distance),\n",
    "            (drone.move_back, random_distance),\n",
    "        ]\n",
    "        \n",
    "        # sample 3 actions at random\n",
    "        sampled_actions = r.sample(action_space, 3)\n",
    "        for action in sampled_actions:\n",
    "            action[0](action[1])\n",
    "            time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the 4 points of a bounding box\n",
    "def find_corners(upper_left: tuple, length: float, width: float) -> list:\n",
    "    \"\"\"\n",
    "    Find the 4 corners of a bounding box, given the upper left corner, length, and width.\n",
    "\n",
    "    Args:\n",
    "        upper_left (tuple): Upper left coordinates of the bounding box.\n",
    "        length (float): Length of the bounding box\n",
    "        width (float): Width of the bounding box\n",
    "\n",
    "    Returns:\n",
    "        corners (list): A list containing the coordinates of the 4 corners of the bounding box.\n",
    "    \"\"\"\n",
    "    corners = []\n",
    "    \n",
    "    upper_right = (upper_left[0] + length, upper_left[1])\n",
    "    lower_left =  (upper_left[0], upper_left[1] + width)\n",
    "    lower_right = (upper_left[0] + length, upper_left[1] + width)\n",
    "    \n",
    "    corners.append(upper_left)\n",
    "    corners.append(upper_right)\n",
    "    corners.append(lower_left)\n",
    "    corners.append(lower_right)\n",
    "    \n",
    "    return corners\n",
    "\n",
    "    \n",
    "# Find the center of a bounding box\n",
    "def find_center(corners: list) -> tuple:\n",
    "    \"\"\"\n",
    "    Find the center coordinates of a bounding box, given the 4 corners of the bounding box.\n",
    "\n",
    "    Args:\n",
    "        corners (list): A list containing the coordinates of the 4 corners of the bounding box.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: Coordinates of the center of the bounding box.\n",
    "    \"\"\"\n",
    "    upper_left, upper_right, lower_left, lower_right = corners\n",
    "    \n",
    "    # create diagonal using upper left and lower right\n",
    "    center_x = (upper_left[0] + upper_right[0]) / 2\n",
    "    center_y = (upper_left[1] + lower_right[1]) / 2\n",
    "    \n",
    "    return(center_x, center_y)\n",
    "\n",
    "\n",
    "# Exploit Function: Input we have a bounding box with 4 corners (or 1 corner + length and width for a more compact representation)\n",
    "def exploit(drone, bbox, use_gpt = False, prompt_template = explore_template):\n",
    "    \"\"\"\n",
    "    Legacy implementation of the Exploit Function: Given the bounding box of a target of interest, execute two transformations to move closer to the object\n",
    "\n",
    "    Args:\n",
    "        drone: Tello (djiteleopy) object that specifies actions to be taken on a DJI Tello drone over WiFi and offers data streaming capabilities.\n",
    "        bbox (list): A list containing the 4 corners of a bounding box.\n",
    "        use_gpt (bool, optional): Whether or not to use GPT prompt for control. Defaults to False.\n",
    "        prompt_template (str, optional): LLM prompt template. Defaults to explore_template.\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    if use_gpt:\n",
    "        prompt(prompt_template)\n",
    "        \n",
    "    distance_to_object = None\n",
    "    angle_to_object = None\n",
    "    height_to_object = None\n",
    "    actions = [\n",
    "        (drone.move_left, distance_to_object),\n",
    "        (drone.move_right, distance_to_object),\n",
    "        (drone.rotate_clockwise, angle_to_object),\n",
    "        (drone.rotate_counter_clockwise, angle_to_object),\n",
    "        (drone.move_forward, distance_to_object),\n",
    "        (drone.move_back, distance_to_object) \n",
    "    ]\n",
    "        \n",
    "    # Step 1: Find out whether or not the drone is facing the object\n",
    "    object_in_frame = False\n",
    "    while object_in_frame == False:\n",
    "        drone.rotate_clockwise(30)\n",
    "    \n",
    "    \n",
    "    # Step 2: Translate the object to the center\n",
    "    bounding_box_center = find_center(bbox)\n",
    "    current_image = drone.get_frame_read().frame\n",
    "    height, width, channel = current_image.shape\n",
    "    frame_center = (width / 2, height / 2)\n",
    "    \n",
    "    delta_y = frame_center[1] - bounding_box_center[1]\n",
    "    delta_x = frame_center[0] - bounding_box_center[0]\n",
    "    \n",
    "    if delta_y < 0:\n",
    "        drone.move_up(abs(delta_y))\n",
    "    else:\n",
    "        drone.move_down(abs(delta_y))\n",
    "    \n",
    "    if delta_x < 0:\n",
    "        drone.move_left(abs(delta_x))\n",
    "    else:\n",
    "        drone.move_right(abs(delta_x))\n",
    "    \n",
    "    # Step 3: Zoom In (move towards the object)\n",
    "    bbox_length = bbox[1][0] - bbox[0][0]\n",
    "    bbox_width = bbox[1][1] - bbox[0][1]\n",
    "    \n",
    "    while bbox_width <= 100 or bbox_length <= 100:\n",
    "        drone.move_forward(10)\n",
    "    \n",
    "    # Step 4: Terminate\n",
    "    return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5940fbd60f4524a89d25f69a9047e7141ce4840794657a7e6183bb38ffdcde84"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
