{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported all modules\n"
     ]
    }
   ],
   "source": [
    "# Import Required Packages\n",
    "import time, cv2, sys, os, torch, re\n",
    "from threading import Thread\n",
    "from djitellopy import Tello\n",
    "import openai\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import random as r\n",
    "from transformers import ViltProcessor, ViltForQuestionAnswering\n",
    "\n",
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Configure Packages\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path+\"/prompts/\")\n",
    "    \n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path+\"/Scripts/\")\n",
    "    \n",
    "# Import Local Packages\n",
    "from vqa_question.v1 import prompt_template as vqa_prompt_template\n",
    "from drone_explore_prompt import prompt_template as explore_template\n",
    "from drone_next_action.v1 import prompt_template as drone_prompt_template\n",
    "\n",
    "from data_collection_utils import take_individual_picture, stream_video, stream_frames, record_streamed_frames\n",
    "\n",
    "print(\"Imported all modules\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize YOLOv8\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolov8n.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coords(obj_name, img_url, verbose=False):\n",
    "    \"\"\"\n",
    "    Function to obtain the bounding box coordinates of an object in an image.\n",
    "\n",
    "    Args:\n",
    "        obj_name (Any Valid YOLO Class): The object of interest.\n",
    "        img_url (str): Location of the image to perform analysis on.\n",
    "        verbose (bool, optional): Whether or not to print out the names of all objects detected within the images. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        result_tuple (tuple(int), tuple(int)): Bounding box coordinates.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    pred = model(img_url)\n",
    "    \n",
    "    if verbose:\n",
    "        print(pred)\n",
    "\n",
    "    # get bouning box coordinates for object\n",
    "    classes = pred[0].boxes.cls\n",
    "\n",
    "    idx_to_name = pred[0].names\n",
    "\n",
    "    names = [idx_to_name[int(i)] for i in classes]\n",
    "    if obj_name not in names:\n",
    "        if verbose:\n",
    "            print(names)\n",
    "        print(time.time() - start_time, 'seconds elapsed')\n",
    "        return None, None\n",
    "    \n",
    "    idx_obj = names.index(obj_name)\n",
    "    coords = pred[0].boxes.xyxy[idx_obj]\n",
    "    if verbose:\n",
    "        print(names)\n",
    "    print(time.time() - start_time, 'seconds elapsed')\n",
    "    \n",
    "    result_tuple = (int(coords[0].item()), int(coords[1].item())), (int(coords[2].item()), int(coords[3].item()))\n",
    "    return result_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_box(img, top_left, bottom_right):\n",
    "    \"\"\"\n",
    "    Draw a bounding box on a given image.\n",
    "\n",
    "    Args:\n",
    "        img (any valid image object): Original image.\n",
    "        top_left (tuple): Top left coordinates of the bounding box.\n",
    "        bottom_right (tuple): Bottom right coordinates of the bounding box.\n",
    "    \"\"\"\n",
    "    rect = cv2.rectangle(img, top_left, bottom_right, (0, 255, 0), 2)\n",
    "    cv2.imshow(\"Video Feed\", rect)\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] tello.py - 122 - Tello instance was initialized. Host: '192.168.10.1'. Port: '8889'.\n",
      "[INFO] tello.py - 437 - Send command: 'command'\n",
      "[INFO] tello.py - 461 - Response command: 'ok'\n"
     ]
    }
   ],
   "source": [
    "# Set up Drone\n",
    "drone = Tello()\n",
    "drone.connect()\n",
    "\n",
    "# Check Battery Levels\n",
    "drone.get_battery()\n",
    "\n",
    "# Initialize variables for bounding box coordinates\n",
    "top_left, bottom_right = None, None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt(prompt, stop_tokens = None):\n",
    "    \"\"\"\n",
    "    Return an LLM Response to a Prompt.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): Original LLM Prompt\n",
    "        stop_tokens (list, optional): List of stop tokens for the LLM. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",\n",
    "        prompt=prompt,\n",
    "        temperature=0.5,\n",
    "        max_tokens=1000,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        best_of=1,\n",
    "        stop=stop_tokens,\n",
    "    )\n",
    "    return response.choices[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Prompt Template for Simple Drone Flight\n",
    "prompt_text=\"\"\"You are writing code to control a drone.\n",
    "Here is a list of commands:\n",
    "    drone.move_left(X)  - move the drone left by X centimeters, where X is between 20 and 500\n",
    "    drone.move_right(X) - move the drone right by X centimeters, where X is between 20 and 500\n",
    "    drone.move_forward(X) - move the drone forward by X centimeters, where X is between 20 and 500\n",
    "    drone.move_back(X) - move the drone back by X centimeters, where X is between 20 and 500\n",
    "    drone.takeoff() - lift off the drone\n",
    "    drone.land() - land the drone\n",
    "    drone.rotate_clockwise(X) - rotate the drone clockwise by X degrees, where X is between 1 and 360\n",
    "    drone.rotate_counter_clockwise(X) - rotate the drone counter-clockwise by X degrees, where X is between 1 and 360\n",
    "\n",
    "Write the code needed for an algorithm to $objective\n",
    "You need to start by taking off with the drone.takeoff() command and end by landing with the drone.land() command.\n",
    "Please insert helpful print statements to document the progress towards the objective.\n",
    "\n",
    "Code:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated Prompt Template which incorporates object detection results to modify trajectory\n",
    "prompt_image=\"\"\"You are writing code to control a drone.\n",
    "Here is a list of commands:\n",
    "    drone.move_left(X)  - move the drone left by X centimeters, where X is between 20 and 50\n",
    "    drone.move_right(X) - move the drone right by X centimeters, where X is between 20 and 50\n",
    "    drone.move_forward(X) - move the drone forward by X centimeters, where X is between 20 and 50\n",
    "    drone.move_back(X) - move the drone back by X centimeters, where X is between 20 and 50\n",
    "    drone.takeoff() - lift off the drone\n",
    "    drone.land() - land the drone\n",
    "    drone.rotate_clockwise(X) - rotate the drone clockwise by X degrees, where X is between 1 and 360\n",
    "    drone.rotate_counter_clockwise(X) - rotate the drone counter-clockwise by X degrees, where X is between 1 and 360\n",
    "    object_detect(X) - takes in the name of an object X, and returns True or False depending on whether the object is in the frame. valid values for X are [bottle, person, chair]\n",
    "\n",
    "Write the code needed for an algorithm to $objective\n",
    "You need to start by taking off with the drone.takeoff() command and end by landing with the drone.land() command.\n",
    "Please insert helpful print statements to document the progress towards the objective.\n",
    "\n",
    "Code:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def object_detect(obj: str) -> bool:\n",
    "    \"\"\"\n",
    "    Detects an object in the frame and returns True or False depending on whether the object is in the frame. If true, the function draws a bounding box around the object of interest.\n",
    "\n",
    "    Args:\n",
    "        obj (str): The name of the object of interest.\n",
    "\n",
    "    Returns:\n",
    "        bool: Whether or not the object of interest is within the image frame.\n",
    "    \"\"\"\n",
    "    # Initialize drone stream\n",
    "    drone.streamon()\n",
    "    time.sleep(10)\n",
    "    \n",
    "    # Obtain live image from drone\n",
    "    img = drone.get_frame_read().frame\n",
    "    img = cv2.resize(img, (360, 240))\n",
    "\n",
    "    # Obtain bounding box coordinates for object and display image + bounding box coordinates\n",
    "    top_left, bottom_right = get_coords(obj, img)\n",
    "    print('coords', top_left, bottom_right)\n",
    "    cv2.imshow(\"image\", img)\n",
    "    cv2.waitKey(1)\n",
    "    \n",
    "    # Plot bounding box if the object is in the frame\n",
    "    if top_left is not None:\n",
    "        print(\"Bottle Found!\")\n",
    "        plot_box(img, top_left=top_left, bottom_right=bottom_right)\n",
    "        time.sleep(10)\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] tello.py - 437 - Send command: 'streamon'\n",
      "[INFO] tello.py - 461 - Response streamon: 'ok'\n",
      "[h264 @ 0x1437da200] non-existing PPS 0 referenced\n",
      "[h264 @ 0x1437da200] non-existing PPS 0 referenced\n",
      "[h264 @ 0x1437da200] decode_slice_header error\n",
      "[h264 @ 0x1437da200] no frame!\n",
      "[h264 @ 0x1437da200] non-existing PPS 0 referenced\n",
      "[h264 @ 0x1437da200] non-existing PPS 0 referenced\n",
      "[h264 @ 0x1437da200] decode_slice_header error\n",
      "[h264 @ 0x1437da200] no frame!\n",
      "[h264 @ 0x1437da200] non-existing PPS 0 referenced\n",
      "[h264 @ 0x1437da200] non-existing PPS 0 referenced\n",
      "[h264 @ 0x1437da200] decode_slice_header error\n",
      "[h264 @ 0x1437da200] no frame!\n",
      "[h264 @ 0x1437da200] non-existing PPS 0 referenced\n",
      "[h264 @ 0x1437da200] non-existing PPS 0 referenced\n",
      "[h264 @ 0x1437da200] decode_slice_header error\n",
      "[h264 @ 0x1437da200] no frame!\n",
      "[h264 @ 0x1437da200] non-existing PPS 0 referenced\n",
      "[h264 @ 0x1437da200] non-existing PPS 0 referenced\n",
      "[h264 @ 0x1437da200] decode_slice_header error\n",
      "[h264 @ 0x1437da200] no frame!\n",
      "[h264 @ 0x1437da200] non-existing PPS 0 referenced\n",
      "[h264 @ 0x1437da200] non-existing PPS 0 referenced\n",
      "[h264 @ 0x1437da200] decode_slice_header error\n",
      "[h264 @ 0x1437da200] no frame!\n",
      "[h264 @ 0x1437da200] non-existing PPS 0 referenced\n",
      "[h264 @ 0x1437da200] non-existing PPS 0 referenced\n",
      "[h264 @ 0x1437da200] decode_slice_header error\n",
      "[h264 @ 0x1437da200] no frame!\n",
      "[h264 @ 0x1437da200] non-existing PPS 0 referenced\n",
      "[h264 @ 0x1437da200] non-existing PPS 0 referenced\n",
      "[h264 @ 0x1437da200] decode_slice_header error\n",
      "[h264 @ 0x1437da200] no frame!\n",
      "[h264 @ 0x1437da200] non-existing PPS 0 referenced\n",
      "[h264 @ 0x1437da200] non-existing PPS 0 referenced\n",
      "[h264 @ 0x1437da200] decode_slice_header error\n",
      "[h264 @ 0x1437da200] no frame!\n",
      "[h264 @ 0x1437da200] non-existing PPS 0 referenced\n",
      "[h264 @ 0x1437da200] non-existing PPS 0 referenced\n",
      "[h264 @ 0x1437da200] decode_slice_header error\n",
      "[h264 @ 0x1437da200] no frame!\n",
      "[h264 @ 0x1437da200] non-existing PPS 0 referenced\n",
      "[h264 @ 0x1437da200] non-existing PPS 0 referenced\n",
      "[h264 @ 0x1437da200] decode_slice_header error\n",
      "[h264 @ 0x1437da200] no frame!\n",
      "[h264 @ 0x1437da200] non-existing PPS 0 referenced\n",
      "[h264 @ 0x1437da200] non-existing PPS 0 referenced\n",
      "[h264 @ 0x1437da200] decode_slice_header error\n",
      "[h264 @ 0x1437da200] no frame!\n",
      "[h264 @ 0x1437da200] non-existing PPS 0 referenced\n",
      "[h264 @ 0x1437da200] non-existing PPS 0 referenced\n",
      "[h264 @ 0x1437da200] decode_slice_header error\n",
      "[h264 @ 0x1437da200] no frame!\n",
      "[h264 @ 0x1437da200] non-existing PPS 0 referenced\n",
      "[h264 @ 0x1437da200] non-existing PPS 0 referenced\n",
      "[h264 @ 0x1437da200] decode_slice_header error\n",
      "[h264 @ 0x1437da200] no frame!\n",
      "[h264 @ 0x1437da200] non-existing PPS 0 referenced\n",
      "[h264 @ 0x1437da200] non-existing PPS 0 referenced\n",
      "[h264 @ 0x1437da200] decode_slice_header error\n",
      "[h264 @ 0x1437da200] no frame!\n",
      "[h264 @ 0x1437da200] non-existing PPS 0 referenced\n",
      "[h264 @ 0x1437da200] non-existing PPS 0 referenced\n",
      "[h264 @ 0x1437da200] decode_slice_header error\n",
      "[h264 @ 0x1437da200] no frame!\n",
      "[h264 @ 0x1437da200] non-existing PPS 0 referenced\n",
      "[h264 @ 0x1437da200] non-existing PPS 0 referenced\n",
      "[h264 @ 0x1437da200] decode_slice_header error\n",
      "[h264 @ 0x1437da200] no frame!\n",
      "[h264 @ 0x1437da200] non-existing PPS 0 referenced\n",
      "[h264 @ 0x1437da200] non-existing PPS 0 referenced\n",
      "[h264 @ 0x1437da200] decode_slice_header error\n",
      "[h264 @ 0x1437da200] no frame!\n",
      "[h264 @ 0x1437da200] non-existing PPS 0 referenced\n",
      "[h264 @ 0x1437da200] non-existing PPS 0 referenced\n",
      "[h264 @ 0x1437da200] decode_slice_header error\n",
      "[h264 @ 0x1437da200] no frame!\n",
      "[h264 @ 0x1437da200] non-existing PPS 0 referenced\n",
      "[h264 @ 0x1437da200] non-existing PPS 0 referenced\n",
      "[h264 @ 0x1437da200] decode_slice_header error\n",
      "[h264 @ 0x1437da200] no frame!\n",
      "[h264 @ 0x1437da200] non-existing PPS 0 referenced\n",
      "[h264 @ 0x1437da200] non-existing PPS 0 referenced\n",
      "[h264 @ 0x1437da200] decode_slice_header error\n",
      "[h264 @ 0x1437da200] no frame!\n",
      "[h264 @ 0x1437da200] non-existing PPS 0 referenced\n",
      "[h264 @ 0x1437da200] non-existing PPS 0 referenced\n",
      "[h264 @ 0x1437da200] decode_slice_header error\n",
      "[h264 @ 0x1437da200] no frame!\n",
      "[h264 @ 0x1437da200] non-existing PPS 0 referenced\n",
      "[h264 @ 0x1437da200] non-existing PPS 0 referenced\n",
      "[h264 @ 0x1437da200] decode_slice_header error\n",
      "[h264 @ 0x1437da200] no frame!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m object_detect(\u001b[39m\"\u001b[39;49m\u001b[39mbottle\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[38], line 4\u001b[0m, in \u001b[0;36mobject_detect\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m      2\u001b[0m drone\u001b[39m.\u001b[39mstreamon()\n\u001b[1;32m      3\u001b[0m time\u001b[39m.\u001b[39msleep(\u001b[39m10\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m img \u001b[39m=\u001b[39m drone\u001b[39m.\u001b[39;49mget_frame_read()\u001b[39m.\u001b[39mframe\n\u001b[1;32m      5\u001b[0m img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mresize(img, (\u001b[39m360\u001b[39m, \u001b[39m240\u001b[39m))\n\u001b[1;32m      6\u001b[0m \u001b[39m# cv2.imshow('a', img)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39m# cv2.waitKey(1)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/djitellopy/enforce_types.py:54\u001b[0m, in \u001b[0;36menforce_types.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m     52\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     53\u001b[0m     check_types(spec, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 54\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/djitellopy/tello.py:420\u001b[0m, in \u001b[0;36mTello.get_frame_read\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbackground_frame_read \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    419\u001b[0m     address \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_udp_video_address()\n\u001b[0;32m--> 420\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbackground_frame_read \u001b[39m=\u001b[39m BackgroundFrameRead(\u001b[39mself\u001b[39;49m, address)  \u001b[39m# also sets self.cap\u001b[39;00m\n\u001b[1;32m    421\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbackground_frame_read\u001b[39m.\u001b[39mstart()\n\u001b[1;32m    422\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbackground_frame_read\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/djitellopy/tello.py:1029\u001b[0m, in \u001b[0;36mBackgroundFrameRead.__init__\u001b[0;34m(self, tello, address)\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, tello, address):\n\u001b[0;32m-> 1029\u001b[0m     tello\u001b[39m.\u001b[39mcap \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mVideoCapture(address)\n\u001b[1;32m   1031\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcap \u001b[39m=\u001b[39m tello\u001b[39m.\u001b[39mcap\n\u001b[1;32m   1033\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcap\u001b[39m.\u001b[39misOpened():\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Test object detection on a bottle in a sample frame\n",
    "object_detect(\"bottle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt the LLM with an objective and print out the resulting LLM-generated action code\n",
    "code_str = prompt(prompt_image.replace(\"$objective\", \"find the bottle\"))\n",
    "print(code_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the LLM-generated action code\n",
    "exec(code_str)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flight Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] tello.py - 437 - Send command: 'takeoff'\n",
      "[INFO] tello.py - 461 - Response takeoff: 'ok'\n"
     ]
    }
   ],
   "source": [
    "drone.takeoff() # launch drone\n",
    "\n",
    "drone.get_battery() # obtain battery levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "def find_center_coord_for_frame_size(size=(360, 240)):\n",
    "    \"\"\"\n",
    "    Find the center coordinates for a frame of a given size.\n",
    "\n",
    "    Args:\n",
    "        size (tuple, optional): Image Frame Size. Defaults to (360, 240).\n",
    "\n",
    "    Returns:\n",
    "        tuple(int): X and Y coordinates of the center.\n",
    "    \"\"\"\n",
    "    return (size[0]//2, size[1]//2)\n",
    "\n",
    "\n",
    "def find_center(top_l: tuple, bottom_r: tuple) -> tuple:\n",
    "    \"\"\"\n",
    "    Find the center coordinates of a bounding box, given the top left and bottom right coordinates\n",
    "\n",
    "    Args:\n",
    "        top_l (tuple): Top left coordinates of the bounding box.\n",
    "        bottom_r (tuple): Bottom right coordinates of the bounding box.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Coordinates of the center of the bounding box.\n",
    "    \"\"\"\n",
    "    top_w, top_h = top_l\n",
    "    bottom_w, bottom_h = bottom_r\n",
    "    center_x = ((bottom_w - top_w) // 2) + top_w\n",
    "    center_y = ((top_h - bottom_h) // 2) + bottom_h\n",
    "\n",
    "    return (center_x, center_y)\n",
    "\n",
    "\n",
    "def get_bbox_width_height(top_l: tuple, bottom_r: tuple) -> tuple:\n",
    "    \"\"\"\n",
    "    Find the width and height of a bounding box given the top left and bottom right coordinates.\n",
    "\n",
    "    Args:\n",
    "        top_l (_type_): Top left coordinates of the bounding box.\n",
    "        bottom_r (_type_): Bottom right coordinates of the bounding box.\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    top_w, top_h = top_l\n",
    "    bottom_w, bottom_h = bottom_r\n",
    "    return (bottom_w - top_w, top_h - bottom_h)\n",
    "\n",
    "\n",
    "def reorient(frame_center: tuple, bbox_center: tuple) -> None:\n",
    "    \"\"\"\n",
    "    Function to reorient the drone reference frame to be centered at the center of the bounding box by moving the drone.\n",
    "\n",
    "    Args:\n",
    "        frame_center (tuple): Center of the drone's image frame.\n",
    "        bbox_center (tuple): Center of the bounding box of the object of interest.\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    frame_x, frame_y = frame_center\n",
    "    bbox_x, bbox_y = bbox_center\n",
    "\n",
    "    if bbox_x > frame_x:\n",
    "        print(\"Move Right\")\n",
    "        move = (bbox_x - frame_x)\n",
    "        print(move)\n",
    "        drone.move_right(move)\n",
    "        \n",
    "    elif bbox_x < frame_x:\n",
    "        print(\"Move Left\")\n",
    "        move = (frame_x - bbox_x)\n",
    "        print(move)\n",
    "        drone.move_left(move)\n",
    "\n",
    "    if bbox_y > frame_y:\n",
    "        print(\"Move Down\")\n",
    "        move = (bbox_y - frame_y)\n",
    "        print(move)\n",
    "        drone.move_down(move)\n",
    "\n",
    "    elif bbox_y < frame_y:\n",
    "        print(\"Move Up\")\n",
    "        move = (frame_y - bbox_y)\n",
    "        print(move)\n",
    "        drone.move_up(move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exploit(top_left, bottom_right):\n",
    "    \"\"\"\n",
    "    Once a drone has locked on to an object or task of interest, this function is called to execute the prompted task. Currently, supported tasks include searching for an object and moving towards it.\n",
    "\n",
    "    Args:\n",
    "        top_left (tuple): Top left coordinates of the bounding box of the object of interest.\n",
    "        bottom_right (tuple): Bottom right coordinates of the bounding box of the object of interest.\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Align drone with object\n",
    "    frame_center = find_center_coord_for_frame_size((360, 240))\n",
    "    print('frame center', frame_center)\n",
    "    bbox_center = find_center(top_left, bottom_right)\n",
    "    print('box center', bbox_center)\n",
    "    reorient(frame_center, bbox_center)\n",
    "\n",
    "    # Go to object\n",
    "    width, height = get_bbox_width_height(top_left, bottom_right)\n",
    "    while width < 360 * 0.8 and height < 240 * 0.8:\n",
    "        print('move forward')\n",
    "        # drone.move_forward(10)\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x136850a00] left block unavailable for requested intra4x4 mode -1\n",
      "[h264 @ 0x136850a00] error while decoding MB 0 34, bytestream 305\n"
     ]
    }
   ],
   "source": [
    "def track():\n",
    "    \"\"\"\n",
    "    Exploration-Exploitation Function: If the object of interest is detected after prompting, the drone takes off and flies towards it.\n",
    "    \"\"\"\n",
    "    drone.streamon()\n",
    "    time.sleep(10)\n",
    "    while True:\n",
    "        img = drone.get_frame_read().frame\n",
    "        img = cv2.resize(img, (360, 240))\n",
    "        top_left, bottom_right = get_coords(\"bottle\", img)\n",
    "        cv2.imshow(\"image\", img)\n",
    "        cv2.waitKey(1)\n",
    "        if top_left is not None:\n",
    "            print(\"Bottle Found!\")\n",
    "            plot_box(img, top_left=top_left, bottom_right=bottom_right)\n",
    "            time.sleep(1)\n",
    "            drone.takeoff()\n",
    "            exploit(top_left=top_left, bottom_right=bottom_right)\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] tello.py - 437 - Send command: 'streamon'\n",
      "[INFO] tello.py - 461 - Response streamon: 'ok'\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 55.8ms\n",
      "Speed: 1.3ms pre-process, 55.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 2 chairs, 46.8ms\n",
      "Speed: 0.3ms pre-process, 46.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 49.4ms\n",
      "Speed: 0.5ms pre-process, 49.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06369614601135254 seconds elapsed\n",
      "0.050498008728027344 seconds elapsed\n",
      "0.053501129150390625 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 1 person, 1 chair, 51.2ms\n",
      "Speed: 0.6ms pre-process, 51.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 47.3ms\n",
      "Speed: 0.6ms pre-process, 47.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 44.5ms\n",
      "Speed: 0.3ms pre-process, 44.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.055480003356933594 seconds elapsed\n",
      "0.051242828369140625 seconds elapsed\n",
      "0.048341989517211914 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 1 person, 1 chair, 44.8ms\n",
      "Speed: 0.4ms pre-process, 44.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 46.4ms\n",
      "Speed: 0.5ms pre-process, 46.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 47.1ms\n",
      "Speed: 0.4ms pre-process, 47.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 2 chairs, 46.4ms\n",
      "Speed: 0.3ms pre-process, 46.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04904484748840332 seconds elapsed\n",
      "0.050071001052856445 seconds elapsed\n",
      "0.05074882507324219 seconds elapsed\n",
      "0.04967093467712402 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 2 chairs, 46.2ms\n",
      "Speed: 0.3ms pre-process, 46.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 43.1ms\n",
      "Speed: 0.4ms pre-process, 43.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 43.8ms\n",
      "Speed: 0.7ms pre-process, 43.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 45.5ms\n",
      "Speed: 0.4ms pre-process, 45.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04967498779296875 seconds elapsed\n",
      "0.04697704315185547 seconds elapsed\n",
      "0.048014163970947266 seconds elapsed\n",
      "0.049790143966674805 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 1 person, 1 chair, 46.0ms\n",
      "Speed: 0.4ms pre-process, 46.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 59.0ms\n",
      "Speed: 0.3ms pre-process, 59.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 46.9ms\n",
      "Speed: 0.4ms pre-process, 46.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 46.7ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04939126968383789 seconds elapsed\n",
      "0.06329512596130371 seconds elapsed\n",
      "0.05090808868408203 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 0.4ms pre-process, 46.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 45.9ms\n",
      "Speed: 0.5ms pre-process, 45.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 45.3ms\n",
      "Speed: 0.4ms pre-process, 45.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 44.0ms\n",
      "Speed: 0.4ms pre-process, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.051113128662109375 seconds elapsed\n",
      "0.049520254135131836 seconds elapsed\n",
      "0.04880023002624512 seconds elapsed\n",
      "0.04790925979614258 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 1 person, 1 chair, 45.3ms\n",
      "Speed: 0.3ms pre-process, 45.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 46.0ms\n",
      "Speed: 0.5ms pre-process, 46.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 45.0ms\n",
      "Speed: 0.3ms pre-process, 45.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 46.5ms\n",
      "Speed: 0.4ms pre-process, 46.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04933810234069824 seconds elapsed\n",
      "0.04945087432861328 seconds elapsed\n",
      "0.048516035079956055 seconds elapsed\n",
      "0.05049920082092285 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 1 person, 1 chair, 48.0ms\n",
      "Speed: 0.4ms pre-process, 48.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 46.6ms\n",
      "Speed: 0.5ms pre-process, 46.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 44.8ms\n",
      "Speed: 0.4ms pre-process, 44.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 46.4ms\n",
      "Speed: 0.4ms pre-process, 46.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.051587820053100586 seconds elapsed\n",
      "0.05057692527770996 seconds elapsed\n",
      "0.048089027404785156 seconds elapsed\n",
      "0.04996204376220703 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 1 person, 1 chair, 46.0ms\n",
      "Speed: 0.4ms pre-process, 46.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 46.0ms\n",
      "Speed: 0.4ms pre-process, 46.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 46.1ms\n",
      "Speed: 0.3ms pre-process, 46.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 45.8ms\n",
      "Speed: 0.5ms pre-process, 45.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.049735069274902344 seconds elapsed\n",
      "0.05014228820800781 seconds elapsed\n",
      "0.04951596260070801 seconds elapsed\n",
      "0.0493621826171875 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 1 person, 1 chair, 46.4ms\n",
      "Speed: 0.3ms pre-process, 46.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 suitcase, 1 chair, 46.1ms\n",
      "Speed: 0.5ms pre-process, 46.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 46.2ms\n",
      "Speed: 0.4ms pre-process, 46.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 44.6ms\n",
      "Speed: 0.3ms pre-process, 44.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.049871206283569336 seconds elapsed\n",
      "0.049887895584106445 seconds elapsed\n",
      "0.04992103576660156 seconds elapsed\n",
      "0.04832100868225098 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 1 person, 1 chair, 46.1ms\n",
      "Speed: 0.3ms pre-process, 46.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 46.9ms\n",
      "Speed: 0.3ms pre-process, 46.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 56.9ms\n",
      "Speed: 1.5ms pre-process, 56.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 45.9ms\n",
      "Speed: 0.5ms pre-process, 45.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04961585998535156 seconds elapsed\n",
      "0.0501861572265625 seconds elapsed\n",
      "0.06284880638122559 seconds elapsed\n",
      "0.04989910125732422 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 2 chairs, 44.5ms\n",
      "Speed: 0.3ms pre-process, 44.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 45.7ms\n",
      "Speed: 0.3ms pre-process, 45.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 46.0ms\n",
      "Speed: 0.5ms pre-process, 46.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 46.1ms\n",
      "Speed: 0.3ms pre-process, 46.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.047638893127441406 seconds elapsed\n",
      "0.04925417900085449 seconds elapsed\n",
      "0.04995107650756836 seconds elapsed\n",
      "0.04970693588256836 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 1 person, 1 chair, 48.1ms\n",
      "Speed: 0.4ms pre-process, 48.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 46.1ms\n",
      "Speed: 0.4ms pre-process, 46.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 46.3ms\n",
      "Speed: 0.4ms pre-process, 46.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 traffic light, 45.6ms\n",
      "Speed: 0.4ms pre-process, 45.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05164217948913574 seconds elapsed\n",
      "0.0503077507019043 seconds elapsed\n",
      "0.04974699020385742 seconds elapsed\n",
      "0.05004072189331055 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 47.8ms\n",
      "Speed: 0.4ms pre-process, 47.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 44.7ms\n",
      "Speed: 0.4ms pre-process, 44.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 48.1ms\n",
      "Speed: 0.4ms pre-process, 48.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 47.7ms\n",
      "Speed: 0.5ms pre-process, 47.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05146503448486328 seconds elapsed\n",
      "0.04817509651184082 seconds elapsed\n",
      "0.05120277404785156 seconds elapsed\n",
      "0.0520930290222168 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 1 airplane, 47.7ms\n",
      "Speed: 0.6ms pre-process, 47.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 4 persons, 1 suitcase, 45.7ms\n",
      "Speed: 0.5ms pre-process, 45.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 4 persons, 1 suitcase, 47.0ms\n",
      "Speed: 0.4ms pre-process, 47.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 46.2ms\n",
      "Speed: 0.5ms pre-process, 46.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.052108049392700195 seconds elapsed\n",
      "0.04957985877990723 seconds elapsed\n",
      "0.05089998245239258 seconds elapsed\n",
      "0.05007195472717285 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 1 person, 1 chair, 47.9ms\n",
      "Speed: 0.4ms pre-process, 47.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 46.7ms\n",
      "Speed: 0.4ms pre-process, 46.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 2 chairs, 49.1ms\n",
      "Speed: 0.5ms pre-process, 49.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 3 chairs, 47.6ms\n",
      "Speed: 0.5ms pre-process, 47.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05205988883972168 seconds elapsed\n",
      "0.05080389976501465 seconds elapsed\n",
      "0.05296206474304199 seconds elapsed\n",
      "0.05162215232849121 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 2 chairs, 60.5ms\n",
      "Speed: 0.3ms pre-process, 60.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 2 chairs, 49.7ms\n",
      "Speed: 0.4ms pre-process, 49.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 bottle, 2 chairs, 46.8ms\n",
      "Speed: 0.4ms pre-process, 46.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06503701210021973 seconds elapsed\n",
      "0.054260969161987305 seconds elapsed\n",
      "0.05086994171142578 seconds elapsed\n",
      "Bottle Found!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 2 persons, 1 bottle, 2 chairs, 46.9ms\n",
      "Speed: 0.4ms pre-process, 46.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 dog, 1 chair, 46.0ms\n",
      "Speed: 0.4ms pre-process, 46.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 bottle, 1 chair, 48.3ms\n",
      "Speed: 0.5ms pre-process, 48.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05104207992553711 seconds elapsed\n",
      "Bottle Found!\n",
      "0.04954791069030762 seconds elapsed\n",
      "0.05220484733581543 seconds elapsed\n",
      "Bottle Found!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 3 persons, 1 dog, 1 baseball bat, 1 bottle, 1 chair, 47.9ms\n",
      "Speed: 0.4ms pre-process, 47.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 dog, 1 bottle, 1 chair, 50.3ms\n",
      "Speed: 0.4ms pre-process, 50.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 bottle, 1 chair, 46.0ms\n",
      "Speed: 0.5ms pre-process, 46.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05202507972717285 seconds elapsed\n",
      "Bottle Found!\n",
      "0.05393624305725098 seconds elapsed\n",
      "Bottle Found!\n",
      "0.049909114837646484 seconds elapsed\n",
      "Bottle Found!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 1 person, 1 bottle, 1 chair, 47.6ms\n",
      "Speed: 0.4ms pre-process, 47.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 45.0ms\n",
      "Speed: 0.4ms pre-process, 45.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 bottle, 1 chair, 1 dining table, 1 toothbrush, 46.2ms\n",
      "Speed: 0.3ms pre-process, 46.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05096793174743652 seconds elapsed\n",
      "Bottle Found!\n",
      "0.04900407791137695 seconds elapsed\n",
      "0.05000805854797363 seconds elapsed\n",
      "Bottle Found!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 1 person, 1 dog, 2 chairs, 45.2ms\n",
      "Speed: 0.3ms pre-process, 45.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 bottle, 1 chair, 45.0ms\n",
      "Speed: 0.4ms pre-process, 45.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 bottle, 3 chairs, 1 toothbrush, 49.9ms\n",
      "Speed: 0.4ms pre-process, 49.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04879903793334961 seconds elapsed\n",
      "0.04911398887634277 seconds elapsed\n",
      "Bottle Found!\n",
      "0.0534968376159668 seconds elapsed\n",
      "Bottle Found!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 2 persons, 1 bottle, 1 chair, 1 toothbrush, 46.8ms\n",
      "Speed: 0.4ms pre-process, 46.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 dog, 1 chair, 43.7ms\n",
      "Speed: 0.4ms pre-process, 43.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 2 chairs, 46.7ms\n",
      "Speed: 0.3ms pre-process, 46.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 chair, 1 toothbrush, 45.3ms\n",
      "Speed: 0.3ms pre-process, 45.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05085110664367676 seconds elapsed\n",
      "Bottle Found!\n",
      "0.047564029693603516 seconds elapsed\n",
      "0.05031085014343262 seconds elapsed\n",
      "0.048774003982543945 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 1 chair, 1 toothbrush, 46.4ms\n",
      "Speed: 0.4ms pre-process, 46.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 chair, 1 toothbrush, 46.6ms\n",
      "Speed: 0.5ms pre-process, 46.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 bottle, 1 chair, 1 toothbrush, 46.2ms\n",
      "Speed: 0.4ms pre-process, 46.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 dog, 1 bottle, 2 chairs, 46.0ms\n",
      "Speed: 0.4ms pre-process, 46.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.050424814224243164 seconds elapsed\n",
      "0.050649166107177734 seconds elapsed\n",
      "0.049916982650756836 seconds elapsed\n",
      "Bottle Found!\n",
      "0.04979872703552246 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 1 bottle, 1 chair, 56.5ms\n",
      "Speed: 0.5ms pre-process, 56.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 3 persons, 2 chairs, 46.1ms\n",
      "Speed: 0.6ms pre-process, 46.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottle Found!\n",
      "0.06119799613952637 seconds elapsed\n",
      "Bottle Found!\n",
      "0.049822092056274414 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 3 persons, 2 chairs, 46.4ms\n",
      "Speed: 0.3ms pre-process, 46.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 3 persons, 1 dog, 1 baseball bat, 2 chairs, 46.1ms\n",
      "Speed: 0.4ms pre-process, 46.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 3 persons, 1 sports ball, 1 baseball bat, 2 chairs, 46.1ms\n",
      "Speed: 0.5ms pre-process, 46.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 baseball bat, 3 chairs, 46.1ms\n",
      "Speed: 0.5ms pre-process, 46.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.050024986267089844 seconds elapsed\n",
      "0.0497739315032959 seconds elapsed\n",
      "0.04977297782897949 seconds elapsed\n",
      "0.04987382888793945 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 2 persons, 1 baseball bat, 3 chairs, 47.7ms\n",
      "Speed: 0.5ms pre-process, 47.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 baseball bat, 3 chairs, 45.8ms\n",
      "Speed: 0.5ms pre-process, 45.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 baseball bat, 3 chairs, 46.2ms\n",
      "Speed: 0.4ms pre-process, 46.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 2 chairs, 1 toothbrush, 46.5ms\n",
      "Speed: 0.5ms pre-process, 46.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0513911247253418 seconds elapsed\n",
      "0.05010485649108887 seconds elapsed\n",
      "0.049996137619018555 seconds elapsed\n",
      "0.050950050354003906 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 2 chairs, 46.0ms\n",
      "Speed: 0.4ms pre-process, 46.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 bird, 1 baseball bat, 1 chair, 1 toothbrush, 45.5ms\n",
      "Speed: 0.3ms pre-process, 45.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 baseball bat, 1 chair, 1 toothbrush, 47.0ms\n",
      "Speed: 0.4ms pre-process, 47.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 baseball bat, 1 chair, 45.9ms\n",
      "Speed: 0.4ms pre-process, 45.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0496981143951416 seconds elapsed\n",
      "0.04941916465759277 seconds elapsed\n",
      "0.05076003074645996 seconds elapsed\n",
      "0.04966402053833008 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 3 persons, 1 baseball bat, 2 chairs, 46.9ms\n",
      "Speed: 0.4ms pre-process, 46.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 2 chairs, 45.6ms\n",
      "Speed: 0.4ms pre-process, 45.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 knife, 1 chair, 46.0ms\n",
      "Speed: 0.3ms pre-process, 46.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 3 persons, 1 chair, 46.0ms\n",
      "Speed: 0.4ms pre-process, 46.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.050505876541137695 seconds elapsed\n",
      "0.049379825592041016 seconds elapsed\n",
      "0.0494382381439209 seconds elapsed\n",
      "0.04944205284118652 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 3 persons, 1 chair, 46.4ms\n",
      "Speed: 0.3ms pre-process, 46.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 3 persons, 46.6ms\n",
      "Speed: 0.4ms pre-process, 46.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 3 persons, 46.3ms\n",
      "Speed: 0.4ms pre-process, 46.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 46.4ms\n",
      "Speed: 0.4ms pre-process, 46.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05037879943847656 seconds elapsed\n",
      "0.05020499229431152 seconds elapsed\n",
      "0.04984092712402344 seconds elapsed\n",
      "0.05025196075439453 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 2 chairs, 46.0ms\n",
      "Speed: 0.4ms pre-process, 46.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 chair, 58.4ms\n",
      "Speed: 0.6ms pre-process, 58.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 toothbrush, 46.1ms\n",
      "Speed: 0.4ms pre-process, 46.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 45.3ms\n",
      "Speed: 0.3ms pre-process, 45.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04950094223022461 seconds elapsed\n",
      "0.06385397911071777 seconds elapsed\n",
      "0.049714088439941406 seconds elapsed\n",
      "0.048996686935424805 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 46.7ms\n",
      "Speed: 0.4ms pre-process, 46.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 toilet, 45.2ms\n",
      "Speed: 0.4ms pre-process, 45.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 44.6ms\n",
      "Speed: 0.5ms pre-process, 44.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 3 persons, 1 knife, 1 chair, 46.5ms\n",
      "Speed: 0.4ms pre-process, 46.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05049300193786621 seconds elapsed\n",
      "0.04877495765686035 seconds elapsed\n",
      "0.048171043395996094 seconds elapsed\n",
      "0.05054306983947754 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 3 persons, 2 chairs, 47.1ms\n",
      "Speed: 0.4ms pre-process, 47.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 3 persons, 1 handbag, 1 chair, 46.2ms\n",
      "Speed: 0.5ms pre-process, 46.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 3 persons, 1 chair, 44.7ms\n",
      "Speed: 0.4ms pre-process, 44.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 4 persons, 1 chair, 47.7ms\n",
      "Speed: 0.3ms pre-process, 47.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0505521297454834 seconds elapsed\n",
      "0.05033588409423828 seconds elapsed\n",
      "0.0486907958984375 seconds elapsed\n",
      "0.051383018493652344 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 4 persons, 1 chair, 46.8ms\n",
      "Speed: 0.5ms pre-process, 46.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 3 persons, 1 chair, 46.6ms\n",
      "Speed: 0.4ms pre-process, 46.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 airplane, 1 chair, 44.3ms\n",
      "Speed: 0.3ms pre-process, 44.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 2 chairs, 46.0ms\n",
      "Speed: 0.4ms pre-process, 46.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05138802528381348 seconds elapsed\n",
      "0.05039715766906738 seconds elapsed\n",
      "0.04858803749084473 seconds elapsed\n",
      "0.049735069274902344 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 2 persons, 1 chair, 45.7ms\n",
      "Speed: 0.4ms pre-process, 45.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 47.2ms\n",
      "Speed: 0.5ms pre-process, 47.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 45.7ms\n",
      "Speed: 0.4ms pre-process, 45.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 sink, 47.9ms\n",
      "Speed: 0.4ms pre-process, 47.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04928016662597656 seconds elapsed\n",
      "0.05103802680969238 seconds elapsed\n",
      "0.0495450496673584 seconds elapsed\n",
      "0.05148172378540039 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 1 chair, 47.1ms\n",
      "Speed: 0.5ms pre-process, 47.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 2 chairs, 45.7ms\n",
      "Speed: 0.4ms pre-process, 45.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 2 chairs, 46.7ms\n",
      "Speed: 0.5ms pre-process, 46.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 2 chairs, 46.9ms\n",
      "Speed: 0.4ms pre-process, 46.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05122995376586914 seconds elapsed\n",
      "0.04958629608154297 seconds elapsed\n",
      "0.05083584785461426 seconds elapsed\n",
      "0.050314903259277344 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 1 person, 1 chair, 57.6ms\n",
      "Speed: 0.5ms pre-process, 57.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 47.5ms\n",
      "Speed: 0.4ms pre-process, 47.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 airplane, 1 chair, 1 sink, 46.8ms\n",
      "Speed: 0.4ms pre-process, 46.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "[h264 @ 0x11702ae00] left block unavailable for requested intra mode\n",
      "[h264 @ 0x11702ae00] error while decoding MB 0 27, bytestream 300\n",
      "0: 448x640 1 person, 1 airplane, 2 chairs, 1 sink, 46.7ms\n",
      "Speed: 0.4ms pre-process, 46.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06206178665161133 seconds elapsed\n",
      "0.05178999900817871 seconds elapsed\n",
      "0.05072903633117676 seconds elapsed\n",
      "0.05081486701965332 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[h264 @ 0x11704fe00] error while decoding MB 28 19, bytestream 360\n",
      "0: 448x640 1 person, 1 chair, 45.5ms\n",
      "Speed: 0.4ms pre-process, 45.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 46.2ms\n",
      "Speed: 0.5ms pre-process, 46.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 45.9ms\n",
      "Speed: 0.4ms pre-process, 45.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 2 chairs, 46.3ms\n",
      "Speed: 0.5ms pre-process, 46.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.049593210220336914 seconds elapsed\n",
      "0.05066394805908203 seconds elapsed\n",
      "0.04971790313720703 seconds elapsed\n",
      "0.05015873908996582 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 2 persons, 1 bottle, 1 chair, 45.5ms\n",
      "Speed: 0.5ms pre-process, 45.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 bottle, 1 chair, 45.5ms\n",
      "Speed: 0.4ms pre-process, 45.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 potted plant, 46.5ms\n",
      "Speed: 0.4ms pre-process, 46.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04986977577209473 seconds elapsed\n",
      "Bottle Found!\n",
      "0.049633026123046875 seconds elapsed\n",
      "Bottle Found!\n",
      "0.05015277862548828 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 1 potted plant, 45.6ms\n",
      "Speed: 0.4ms pre-process, 45.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 potted plant, 45.6ms\n",
      "Speed: 0.5ms pre-process, 45.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 2 airplanes, 1 potted plant, 46.3ms\n",
      "Speed: 0.5ms pre-process, 46.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 airplane, 1 chair, 1 potted plant, 47.7ms\n",
      "Speed: 0.4ms pre-process, 47.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.049798011779785156 seconds elapsed\n",
      "0.049529075622558594 seconds elapsed\n",
      "0.05006098747253418 seconds elapsed\n",
      "0.05159497261047363 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 2 persons, 1 bottle, 1 chair, 1 potted plant, 45.2ms\n",
      "Speed: 0.4ms pre-process, 45.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 2 bottles, 1 chair, 1 potted plant, 46.9ms\n",
      "Speed: 0.4ms pre-process, 46.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 potted plant, 46.1ms\n",
      "Speed: 0.4ms pre-process, 46.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.048982858657836914 seconds elapsed\n",
      "Bottle Found!\n",
      "0.051323890686035156 seconds elapsed\n",
      "Bottle Found!\n",
      "0.04973411560058594 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 1 person, 2 bottles, 1 potted plant, 48.2ms\n",
      "Speed: 0.5ms pre-process, 48.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 2 bottles, 1 chair, 1 potted plant, 48.8ms\n",
      "Speed: 0.6ms pre-process, 48.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 2 bottles, 1 chair, 1 potted plant, 47.8ms\n",
      "Speed: 0.5ms pre-process, 47.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05247306823730469 seconds elapsed\n",
      "Bottle Found!\n",
      "0.05277085304260254 seconds elapsed\n",
      "Bottle Found!\n",
      "0.05173301696777344 seconds elapsed\n",
      "Bottle Found!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 1 person, 2 bottles, 1 chair, 1 potted plant, 47.0ms\n",
      "Speed: 0.5ms pre-process, 47.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 bottle, 1 chair, 1 potted plant, 46.1ms\n",
      "Speed: 0.4ms pre-process, 46.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 bottle, 1 chair, 1 potted plant, 56.5ms\n",
      "Speed: 0.5ms pre-process, 56.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05108785629272461 seconds elapsed\n",
      "Bottle Found!\n",
      "0.049781084060668945 seconds elapsed\n",
      "Bottle Found!\n",
      "0.06086015701293945 seconds elapsed\n",
      "Bottle Found!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 1 person, 1 bottle, 1 chair, 1 potted plant, 47.8ms\n",
      "Speed: 0.6ms pre-process, 47.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 2 bottles, 1 chair, 1 potted plant, 47.9ms\n",
      "Speed: 0.5ms pre-process, 47.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 bottle, 1 chair, 1 potted plant, 45.3ms\n",
      "Speed: 0.5ms pre-process, 45.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05221414566040039 seconds elapsed\n",
      "Bottle Found!\n",
      "0.05187106132507324 seconds elapsed\n",
      "Bottle Found!\n",
      "0.04943704605102539 seconds elapsed\n",
      "Bottle Found!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 1 person, 1 potted plant, 46.8ms\n",
      "Speed: 0.4ms pre-process, 46.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 potted plant, 46.7ms\n",
      "Speed: 0.5ms pre-process, 46.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 46.6ms\n",
      "Speed: 0.4ms pre-process, 46.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 potted plant, 45.6ms\n",
      "Speed: 0.3ms pre-process, 45.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05091404914855957 seconds elapsed\n",
      "0.05101799964904785 seconds elapsed\n",
      "0.05016922950744629 seconds elapsed\n",
      "0.04958605766296387 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 1 person, 1 potted plant, 46.3ms\n",
      "Speed: 0.4ms pre-process, 46.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 suitcase, 1 cup, 1 potted plant, 45.6ms\n",
      "Speed: 0.5ms pre-process, 45.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 suitcase, 1 potted plant, 47.3ms\n",
      "Speed: 0.5ms pre-process, 47.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 47.9ms\n",
      "Speed: 0.3ms pre-process, 47.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.049868106842041016 seconds elapsed\n",
      "0.05006098747253418 seconds elapsed\n",
      "0.051190853118896484 seconds elapsed\n",
      "0.05117487907409668 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 1 person, 1 potted plant, 47.2ms\n",
      "Speed: 0.6ms pre-process, 47.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 potted plant, 47.1ms\n",
      "Speed: 0.5ms pre-process, 47.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 potted plant, 46.1ms\n",
      "Speed: 0.6ms pre-process, 46.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 potted plant, 47.9ms\n",
      "Speed: 0.5ms pre-process, 47.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05176496505737305 seconds elapsed\n",
      "0.05126810073852539 seconds elapsed\n",
      "0.05020904541015625 seconds elapsed\n",
      "0.05153083801269531 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 2 persons, 1 potted plant, 46.8ms\n",
      "Speed: 0.4ms pre-process, 46.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 potted plant, 47.6ms\n",
      "Speed: 0.3ms pre-process, 47.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 potted plant, 45.8ms\n",
      "Speed: 0.4ms pre-process, 45.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 cup, 1 chair, 1 potted plant, 46.8ms\n",
      "Speed: 0.4ms pre-process, 46.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0500798225402832 seconds elapsed\n",
      "0.050901174545288086 seconds elapsed\n",
      "0.04916882514953613 seconds elapsed\n",
      "0.050586700439453125 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 2 persons, 1 cup, 1 chair, 1 potted plant, 47.9ms\n",
      "Speed: 0.5ms pre-process, 47.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 47.2ms\n",
      "Speed: 0.5ms pre-process, 47.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 47.0ms\n",
      "Speed: 0.5ms pre-process, 47.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 cup, 1 chair, 1 potted plant, 57.7ms\n",
      "Speed: 0.4ms pre-process, 57.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05139517784118652 seconds elapsed\n",
      "0.051142215728759766 seconds elapsed\n",
      "0.050756216049194336 seconds elapsed\n",
      "0.06234478950500488 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 47.9ms\n",
      "Speed: 0.6ms pre-process, 47.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 cup, 1 chair, 1 potted plant, 46.3ms\n",
      "Speed: 0.4ms pre-process, 46.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 46.9ms\n",
      "Speed: 0.3ms pre-process, 46.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 cup, 1 chair, 1 potted plant, 48.5ms\n",
      "Speed: 0.4ms pre-process, 48.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.052117109298706055 seconds elapsed\n",
      "0.050511837005615234 seconds elapsed\n",
      "0.05087614059448242 seconds elapsed\n",
      "0.052178144454956055 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 2 persons, 1 cup, 1 chair, 1 potted plant, 47.0ms\n",
      "Speed: 0.3ms pre-process, 47.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 cup, 1 chair, 1 potted plant, 47.6ms\n",
      "Speed: 0.4ms pre-process, 47.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 cup, 1 chair, 1 potted plant, 47.4ms\n",
      "Speed: 0.4ms pre-process, 47.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 45.6ms\n",
      "Speed: 0.3ms pre-process, 45.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.051373958587646484 seconds elapsed\n",
      "0.05117392539978027 seconds elapsed\n",
      "0.05144906044006348 seconds elapsed\n",
      "0.04951310157775879 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 1 cat, 1 chair, 2 potted plants, 51.7ms\n",
      "Speed: 0.5ms pre-process, 51.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 51.1ms\n",
      "Speed: 0.4ms pre-process, 51.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 3 persons, 1 chair, 1 potted plant, 48.9ms\n",
      "Speed: 0.5ms pre-process, 48.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.055969953536987305 seconds elapsed\n",
      "0.055242061614990234 seconds elapsed\n",
      "0.053562164306640625 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 3 persons, 1 chair, 1 potted plant, 52.3ms\n",
      "Speed: 0.5ms pre-process, 52.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 4 persons, 1 airplane, 1 chair, 1 potted plant, 53.5ms\n",
      "Speed: 0.6ms pre-process, 53.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 1 vase, 54.1ms\n",
      "Speed: 0.4ms pre-process, 54.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05677604675292969 seconds elapsed\n",
      "0.05765414237976074 seconds elapsed\n",
      "0.058328866958618164 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 1 person, 1 airplane, 1 chair, 1 potted plant, 53.6ms\n",
      "Speed: 0.5ms pre-process, 53.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 53.9ms\n",
      "Speed: 0.5ms pre-process, 53.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 47.0ms\n",
      "Speed: 0.4ms pre-process, 47.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 48.4ms\n",
      "Speed: 0.4ms pre-process, 48.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0585782527923584 seconds elapsed\n",
      "0.05903267860412598 seconds elapsed\n",
      "0.05069398880004883 seconds elapsed\n",
      "0.052288055419921875 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 47.0ms\n",
      "Speed: 0.4ms pre-process, 47.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 47.2ms\n",
      "Speed: 0.3ms pre-process, 47.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 50.0ms\n",
      "Speed: 0.4ms pre-process, 50.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 56.0ms\n",
      "Speed: 0.4ms pre-process, 56.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.051303863525390625 seconds elapsed\n",
      "0.051069021224975586 seconds elapsed\n",
      "0.05358695983886719 seconds elapsed\n",
      "0.06003880500793457 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 52.0ms\n",
      "Speed: 0.5ms pre-process, 52.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 48.6ms\n",
      "Speed: 0.5ms pre-process, 48.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 46.9ms\n",
      "Speed: 0.5ms pre-process, 46.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 49.1ms\n",
      "Speed: 0.5ms pre-process, 49.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05706906318664551 seconds elapsed\n",
      "0.052551984786987305 seconds elapsed\n",
      "0.05103802680969238 seconds elapsed\n",
      "0.05283498764038086 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 1 suitcase, 1 chair, 1 potted plant, 48.1ms\n",
      "Speed: 0.4ms pre-process, 48.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 suitcase, 1 chair, 1 potted plant, 46.9ms\n",
      "Speed: 0.4ms pre-process, 46.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 suitcase, 1 chair, 1 potted plant, 1 laptop, 46.4ms\n",
      "Speed: 0.4ms pre-process, 46.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 46.8ms\n",
      "Speed: 0.5ms pre-process, 46.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.052002906799316406 seconds elapsed\n",
      "0.0510711669921875 seconds elapsed\n",
      "0.0504000186920166 seconds elapsed\n",
      "0.05108284950256348 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 46.5ms\n",
      "Speed: 0.5ms pre-process, 46.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 46.7ms\n",
      "Speed: 0.5ms pre-process, 46.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 45.6ms\n",
      "Speed: 0.4ms pre-process, 45.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 47.4ms\n",
      "Speed: 0.5ms pre-process, 47.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05058002471923828 seconds elapsed\n",
      "0.05054807662963867 seconds elapsed\n",
      "0.04952120780944824 seconds elapsed\n",
      "0.05129289627075195 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 1 person, 1 chair, 1 potted plant, 48.3ms\n",
      "Speed: 0.4ms pre-process, 48.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 47.0ms\n",
      "Speed: 0.3ms pre-process, 47.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 suitcase, 1 chair, 47.0ms\n",
      "Speed: 0.3ms pre-process, 47.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 47.5ms\n",
      "Speed: 0.5ms pre-process, 47.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05252408981323242 seconds elapsed\n",
      "0.05064797401428223 seconds elapsed\n",
      "0.050789833068847656 seconds elapsed\n",
      "0.051525115966796875 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 1 chair, 45.8ms\n",
      "Speed: 0.3ms pre-process, 45.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 46.3ms\n",
      "Speed: 0.5ms pre-process, 46.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 47.4ms\n",
      "Speed: 0.5ms pre-process, 47.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 47.6ms\n",
      "Speed: 0.5ms pre-process, 47.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04987382888793945 seconds elapsed\n",
      "0.050126075744628906 seconds elapsed\n",
      "0.05175614356994629 seconds elapsed\n",
      "0.05121493339538574 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 48.3ms\n",
      "Speed: 0.4ms pre-process, 48.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 48.1ms\n",
      "Speed: 0.4ms pre-process, 48.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 airplane, 1 chair, 1 potted plant, 47.5ms\n",
      "Speed: 0.5ms pre-process, 47.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 47.7ms\n",
      "Speed: 0.6ms pre-process, 47.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05222129821777344 seconds elapsed\n",
      "0.051741838455200195 seconds elapsed\n",
      "0.05143404006958008 seconds elapsed\n",
      "0.051676034927368164 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 60.9ms\n",
      "Speed: 0.4ms pre-process, 60.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 bottle, 1 chair, 1 potted plant, 50.4ms\n",
      "Speed: 0.5ms pre-process, 50.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 bottle, 1 chair, 1 potted plant, 49.2ms\n",
      "Speed: 0.4ms pre-process, 49.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06501579284667969 seconds elapsed\n",
      "0.05468177795410156 seconds elapsed\n",
      "Bottle Found!\n",
      "0.05278277397155762 seconds elapsed\n",
      "Bottle Found!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 49.0ms\n",
      "Speed: 0.3ms pre-process, 49.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 3 persons, 1 chair, 1 potted plant, 48.4ms\n",
      "Speed: 0.3ms pre-process, 48.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 48.7ms\n",
      "Speed: 0.3ms pre-process, 48.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 bottle, 1 potted plant, 46.4ms\n",
      "Speed: 0.4ms pre-process, 46.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.053350210189819336 seconds elapsed\n",
      "0.05305910110473633 seconds elapsed\n",
      "0.052316904067993164 seconds elapsed\n",
      "0.05092215538024902 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 1 bottle, 1 chair, 1 potted plant, 1 remote, 47.4ms\n",
      "Speed: 0.4ms pre-process, 47.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 bottle, 1 chair, 1 potted plant, 1 remote, 46.2ms\n",
      "Speed: 0.4ms pre-process, 46.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottle Found!\n",
      "0.0511479377746582 seconds elapsed\n",
      "Bottle Found!\n",
      "0.05053305625915527 seconds elapsed\n",
      "Bottle Found!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 1 person, 1 chair, 1 potted plant, 1 remote, 48.8ms\n",
      "Speed: 0.4ms pre-process, 48.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 potted plant, 47.6ms\n",
      "Speed: 0.5ms pre-process, 47.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 52.9ms\n",
      "Speed: 0.5ms pre-process, 52.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 47.4ms\n",
      "Speed: 0.6ms pre-process, 47.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.052720069885253906 seconds elapsed\n",
      "0.05197405815124512 seconds elapsed\n",
      "0.0573272705078125 seconds elapsed\n",
      "0.051499128341674805 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 1 potted plant, 48.0ms\n",
      "Speed: 0.4ms pre-process, 48.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 potted plant, 46.1ms\n",
      "Speed: 0.3ms pre-process, 46.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 47.7ms\n",
      "Speed: 0.4ms pre-process, 47.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 potted plant, 47.0ms\n",
      "Speed: 0.4ms pre-process, 47.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05205106735229492 seconds elapsed\n",
      "0.05012679100036621 seconds elapsed\n",
      "0.05132699012756348 seconds elapsed\n",
      "0.05101490020751953 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 1 airplane, 1 potted plant, 48.2ms\n",
      "Speed: 0.4ms pre-process, 48.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 potted plant, 47.2ms\n",
      "Speed: 0.5ms pre-process, 47.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 potted plant, 47.9ms\n",
      "Speed: 0.4ms pre-process, 47.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 airplane, 1 potted plant, 47.5ms\n",
      "Speed: 0.4ms pre-process, 47.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05199790000915527 seconds elapsed\n",
      "0.050702810287475586 seconds elapsed\n",
      "0.05217409133911133 seconds elapsed\n",
      "0.0511479377746582 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 1 airplane, 1 potted plant, 45.6ms\n",
      "Speed: 0.4ms pre-process, 45.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 airplane, 1 potted plant, 47.9ms\n",
      "Speed: 0.4ms pre-process, 47.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 airplane, 1 potted plant, 56.2ms\n",
      "Speed: 0.4ms pre-process, 56.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04950523376464844 seconds elapsed\n",
      "0.051796913146972656 seconds elapsed\n",
      "0.06159400939941406 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 1 person, 1 airplane, 1 potted plant, 50.7ms\n",
      "Speed: 0.6ms pre-process, 50.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 48.3ms\n",
      "Speed: 0.4ms pre-process, 48.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 potted plant, 47.5ms\n",
      "Speed: 0.3ms pre-process, 47.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 potted plant, 46.6ms\n",
      "Speed: 0.5ms pre-process, 46.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05485391616821289 seconds elapsed\n",
      "0.051879167556762695 seconds elapsed\n",
      "0.0508270263671875 seconds elapsed\n",
      "0.05026817321777344 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 2 persons, 1 potted plant, 48.0ms\n",
      "Speed: 0.4ms pre-process, 48.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 potted plant, 1 laptop, 47.5ms\n",
      "Speed: 0.5ms pre-process, 47.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 potted plant, 1 laptop, 47.5ms\n",
      "Speed: 0.3ms pre-process, 47.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 airplane, 1 potted plant, 47.0ms\n",
      "Speed: 0.4ms pre-process, 47.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05157184600830078 seconds elapsed\n",
      "0.05143427848815918 seconds elapsed\n",
      "0.05143904685974121 seconds elapsed\n",
      "0.05113816261291504 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 1 train, 1 potted plant, 46.2ms\n",
      "Speed: 0.4ms pre-process, 46.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 potted plant, 1 laptop, 47.5ms\n",
      "Speed: 0.3ms pre-process, 47.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 potted plant, 47.1ms\n",
      "Speed: 0.4ms pre-process, 47.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 potted plant, 46.4ms\n",
      "Speed: 0.3ms pre-process, 46.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05061793327331543 seconds elapsed\n",
      "0.05137515068054199 seconds elapsed\n",
      "0.051096200942993164 seconds elapsed\n",
      "0.05049490928649902 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 2 persons, 1 potted plant, 1 laptop, 47.6ms\n",
      "Speed: 0.3ms pre-process, 47.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 potted plant, 1 laptop, 46.5ms\n",
      "Speed: 0.4ms pre-process, 46.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 potted plant, 1 laptop, 1 remote, 47.7ms\n",
      "Speed: 0.4ms pre-process, 47.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 potted plant, 1 laptop, 1 remote, 46.2ms\n",
      "Speed: 0.4ms pre-process, 46.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.051506996154785156 seconds elapsed\n",
      "0.05055403709411621 seconds elapsed\n",
      "0.0514218807220459 seconds elapsed\n",
      "0.05030083656311035 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 2 persons, 1 potted plant, 1 laptop, 1 remote, 47.6ms\n",
      "Speed: 0.4ms pre-process, 47.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 potted plant, 47.9ms\n",
      "Speed: 0.5ms pre-process, 47.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 potted plant, 46.5ms\n",
      "Speed: 0.4ms pre-process, 46.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 potted plant, 1 laptop, 47.5ms\n",
      "Speed: 0.4ms pre-process, 47.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05109381675720215 seconds elapsed\n",
      "0.051837921142578125 seconds elapsed\n",
      "0.05033111572265625 seconds elapsed\n",
      "0.05157303810119629 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 2 persons, 1 potted plant, 1 laptop, 1 remote, 46.3ms\n",
      "Speed: 0.4ms pre-process, 46.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 1 laptop, 46.5ms\n",
      "Speed: 0.5ms pre-process, 46.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 47.6ms\n",
      "Speed: 0.5ms pre-process, 47.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 45.5ms\n",
      "Speed: 0.3ms pre-process, 45.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.050115108489990234 seconds elapsed\n",
      "0.05075383186340332 seconds elapsed\n",
      "0.05127596855163574 seconds elapsed\n",
      "0.04912900924682617 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 2 persons, 2 chairs, 1 potted plant, 61.8ms\n",
      "Speed: 0.5ms pre-process, 61.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 47.9ms\n",
      "Speed: 0.5ms pre-process, 47.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 47.0ms\n",
      "Speed: 0.3ms pre-process, 47.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 46.9ms\n",
      "Speed: 0.4ms pre-process, 46.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06581568717956543 seconds elapsed\n",
      "0.05194091796875 seconds elapsed\n",
      "0.05069088935852051 seconds elapsed\n",
      "0.051032066345214844 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 45.9ms\n",
      "Speed: 0.5ms pre-process, 45.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 2 chairs, 1 potted plant, 46.6ms\n",
      "Speed: 0.3ms pre-process, 46.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 47.8ms\n",
      "Speed: 0.4ms pre-process, 47.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 48.0ms\n",
      "Speed: 0.4ms pre-process, 48.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04945087432861328 seconds elapsed\n",
      "0.05002903938293457 seconds elapsed\n",
      "0.05185198783874512 seconds elapsed\n",
      "0.051633358001708984 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 45.6ms\n",
      "Speed: 0.4ms pre-process, 45.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 potted plant, 1 laptop, 47.7ms\n",
      "Speed: 0.5ms pre-process, 47.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 potted plant, 1 laptop, 1 remote, 47.3ms\n",
      "Speed: 0.3ms pre-process, 47.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 train, 1 potted plant, 45.0ms\n",
      "Speed: 0.4ms pre-process, 45.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04973793029785156 seconds elapsed\n",
      "0.05229783058166504 seconds elapsed\n",
      "0.050968170166015625 seconds elapsed\n",
      "0.049041032791137695 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 3 persons, 1 chair, 1 potted plant, 1 laptop, 47.3ms\n",
      "Speed: 0.5ms pre-process, 47.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 3 persons, 1 chair, 1 potted plant, 1 laptop, 47.3ms\n",
      "Speed: 0.4ms pre-process, 47.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 1 laptop, 48.2ms\n",
      "Speed: 0.4ms pre-process, 48.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 1 laptop, 45.5ms\n",
      "Speed: 0.4ms pre-process, 45.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.051103830337524414 seconds elapsed\n",
      "0.05094599723815918 seconds elapsed\n",
      "0.05230569839477539 seconds elapsed\n",
      "0.048996925354003906 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 46.6ms\n",
      "Speed: 0.4ms pre-process, 46.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 46.7ms\n",
      "Speed: 0.3ms pre-process, 46.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 45.6ms\n",
      "Speed: 0.4ms pre-process, 45.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 3 persons, 1 chair, 1 potted plant, 47.1ms\n",
      "Speed: 0.3ms pre-process, 47.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.050161123275756836 seconds elapsed\n",
      "0.05010509490966797 seconds elapsed\n",
      "0.04913783073425293 seconds elapsed\n",
      "0.05145692825317383 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 2 persons, 1 potted plant, 50.0ms\n",
      "Speed: 0.4ms pre-process, 50.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 1 laptop, 47.1ms\n",
      "Speed: 0.4ms pre-process, 47.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 47.9ms\n",
      "Speed: 0.5ms pre-process, 47.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 potted plant, 46.8ms\n",
      "Speed: 0.4ms pre-process, 46.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05371403694152832 seconds elapsed\n",
      "0.050868988037109375 seconds elapsed\n",
      "0.051564931869506836 seconds elapsed\n",
      "0.05054593086242676 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 2 persons, 1 potted plant, 59.4ms\n",
      "Speed: 0.4ms pre-process, 59.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 potted plant, 49.5ms\n",
      "Speed: 0.5ms pre-process, 49.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 3 persons, 1 potted plant, 1 laptop, 46.2ms\n",
      "Speed: 0.5ms pre-process, 46.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 3 persons, 1 potted plant, 1 laptop, 1 remote, 47.0ms\n",
      "Speed: 0.4ms pre-process, 47.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06351900100708008 seconds elapsed\n",
      "0.05343174934387207 seconds elapsed\n",
      "0.049982309341430664 seconds elapsed\n",
      "0.0507352352142334 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 1 remote, 44.9ms\n",
      "Speed: 0.5ms pre-process, 44.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 1 laptop, 1 remote, 45.5ms\n",
      "Speed: 0.5ms pre-process, 45.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 3 persons, 1 chair, 1 potted plant, 1 laptop, 1 remote, 45.9ms\n",
      "Speed: 0.5ms pre-process, 45.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 3 persons, 1 chair, 1 potted plant, 1 laptop, 1 remote, 47.5ms\n",
      "Speed: 0.4ms pre-process, 47.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04951882362365723 seconds elapsed\n",
      "0.05006599426269531 seconds elapsed\n",
      "0.04963517189025879 seconds elapsed\n",
      "0.051236867904663086 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 3 persons, 1 chair, 1 potted plant, 1 laptop, 1 remote, 45.9ms\n",
      "Speed: 0.5ms pre-process, 45.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 3 persons, 1 chair, 1 potted plant, 1 laptop, 1 remote, 47.2ms\n",
      "Speed: 0.4ms pre-process, 47.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 3 persons, 2 chairs, 1 potted plant, 1 laptop, 1 remote, 48.1ms\n",
      "Speed: 0.3ms pre-process, 48.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 1 laptop, 1 remote, 45.2ms\n",
      "Speed: 0.3ms pre-process, 45.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.050115108489990234 seconds elapsed\n",
      "0.051013946533203125 seconds elapsed\n",
      "0.051918983459472656 seconds elapsed\n",
      "0.048809051513671875 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 3 persons, 1 chair, 1 potted plant, 1 laptop, 1 remote, 47.5ms\n",
      "Speed: 0.5ms pre-process, 47.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 1 laptop, 1 remote, 47.5ms\n",
      "Speed: 0.3ms pre-process, 47.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 1 laptop, 47.5ms\n",
      "Speed: 0.4ms pre-process, 47.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 1 laptop, 1 remote, 47.8ms\n",
      "Speed: 0.5ms pre-process, 47.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.051232099533081055 seconds elapsed\n",
      "0.05155301094055176 seconds elapsed\n",
      "0.0515289306640625 seconds elapsed\n",
      "0.05222582817077637 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 3 persons, 1 airplane, 1 chair, 1 potted plant, 1 laptop, 47.9ms\n",
      "Speed: 0.4ms pre-process, 47.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 3 persons, 1 airplane, 1 chair, 1 potted plant, 1 laptop, 47.1ms\n",
      "Speed: 0.3ms pre-process, 47.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 airplane, 1 chair, 1 potted plant, 1 laptop, 46.9ms\n",
      "Speed: 0.5ms pre-process, 46.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 1 laptop, 46.5ms\n",
      "Speed: 0.4ms pre-process, 46.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.051670074462890625 seconds elapsed\n",
      "0.05132699012756348 seconds elapsed\n",
      "0.05104827880859375 seconds elapsed\n",
      "0.05078291893005371 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 1 laptop, 47.1ms\n",
      "Speed: 0.4ms pre-process, 47.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 1 laptop, 1 remote, 47.2ms\n",
      "Speed: 0.4ms pre-process, 47.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 3 persons, 1 potted plant, 46.3ms\n",
      "Speed: 0.4ms pre-process, 46.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 3 persons, 1 chair, 1 potted plant, 46.7ms\n",
      "Speed: 0.3ms pre-process, 46.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05076932907104492 seconds elapsed\n",
      "0.05074000358581543 seconds elapsed\n",
      "0.0502011775970459 seconds elapsed\n",
      "0.050837039947509766 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[h264 @ 0x136851000] error while decoding MB 33 34, bytestream -5\n",
      "0: 448x640 3 persons, 1 chair, 1 potted plant, 59.8ms\n",
      "Speed: 0.5ms pre-process, 59.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 3 persons, 1 potted plant, 1 remote, 49.2ms\n",
      "Speed: 0.4ms pre-process, 49.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 potted plant, 1 remote, 46.0ms\n",
      "Speed: 0.4ms pre-process, 46.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 potted plant, 1 laptop, 1 remote, 46.6ms\n",
      "Speed: 0.3ms pre-process, 46.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06539297103881836 seconds elapsed\n",
      "0.05327200889587402 seconds elapsed\n",
      "0.05044102668762207 seconds elapsed\n",
      "0.050171852111816406 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 2 persons, 1 potted plant, 1 laptop, 1 remote, 45.9ms\n",
      "Speed: 0.4ms pre-process, 45.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 1 laptop, 1 remote, 46.7ms\n",
      "Speed: 0.4ms pre-process, 46.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 2 laptops, 47.6ms\n",
      "Speed: 0.4ms pre-process, 47.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 2 laptops, 49.2ms\n",
      "Speed: 0.4ms pre-process, 49.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04964089393615723 seconds elapsed\n",
      "0.05144667625427246 seconds elapsed\n",
      "0.0512998104095459 seconds elapsed\n",
      "0.052835941314697266 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 3 persons, 1 chair, 1 potted plant, 1 laptop, 47.1ms\n",
      "Speed: 0.4ms pre-process, 47.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 1 laptop, 47.4ms\n",
      "Speed: 0.3ms pre-process, 47.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 1 laptop, 46.9ms\n",
      "Speed: 0.4ms pre-process, 46.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 46.4ms\n",
      "Speed: 0.4ms pre-process, 46.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05125093460083008 seconds elapsed\n",
      "0.05160212516784668 seconds elapsed\n",
      "0.05073904991149902 seconds elapsed\n",
      "0.050195932388305664 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 3 persons, 1 chair, 1 potted plant, 48.6ms\n",
      "Speed: 0.4ms pre-process, 48.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 3 persons, 1 chair, 1 potted plant, 47.2ms\n",
      "Speed: 0.4ms pre-process, 47.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 47.2ms\n",
      "Speed: 0.4ms pre-process, 47.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 47.7ms\n",
      "Speed: 0.4ms pre-process, 47.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.052446842193603516 seconds elapsed\n",
      "0.05081009864807129 seconds elapsed\n",
      "0.051178932189941406 seconds elapsed\n",
      "0.051744937896728516 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 1 laptop, 47.8ms\n",
      "Speed: 0.5ms pre-process, 47.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 4 persons, 1 chair, 1 potted plant, 1 laptop, 47.5ms\n",
      "Speed: 0.4ms pre-process, 47.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 1 laptop, 47.0ms\n",
      "Speed: 0.5ms pre-process, 47.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 1 remote, 46.9ms\n",
      "Speed: 0.3ms pre-process, 46.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05188798904418945 seconds elapsed\n",
      "0.051403045654296875 seconds elapsed\n",
      "0.0514678955078125 seconds elapsed\n",
      "0.05069422721862793 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 1 remote, 48.8ms\n",
      "Speed: 0.5ms pre-process, 48.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 3 persons, 1 chair, 1 potted plant, 1 remote, 47.3ms\n",
      "Speed: 0.3ms pre-process, 47.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 1 remote, 47.9ms\n",
      "Speed: 0.3ms pre-process, 47.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 3 persons, 1 chair, 1 potted plant, 1 remote, 47.4ms\n",
      "Speed: 0.5ms pre-process, 47.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05300784111022949 seconds elapsed\n",
      "0.05081486701965332 seconds elapsed\n",
      "0.051321983337402344 seconds elapsed\n",
      "0.05127215385437012 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 3 persons, 1 chair, 1 potted plant, 58.5ms\n",
      "Speed: 0.4ms pre-process, 58.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 48.5ms\n",
      "Speed: 0.5ms pre-process, 48.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 49.0ms\n",
      "Speed: 0.4ms pre-process, 49.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 3 persons, 1 chair, 1 potted plant, 1 laptop, 46.2ms\n",
      "Speed: 0.4ms pre-process, 46.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06330180168151855 seconds elapsed\n",
      "0.05281209945678711 seconds elapsed\n",
      "0.05245089530944824 seconds elapsed\n",
      "0.05056190490722656 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 2 persons, 1 potted plant, 1 laptop, 47.2ms\n",
      "Speed: 0.5ms pre-process, 47.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 potted plant, 1 laptop, 48.1ms\n",
      "Speed: 0.4ms pre-process, 48.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 potted plant, 1 laptop, 1 remote, 48.9ms\n",
      "Speed: 0.8ms pre-process, 48.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 airplane, 1 potted plant, 1 laptop, 45.6ms\n",
      "Speed: 0.3ms pre-process, 45.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.051531076431274414 seconds elapsed\n",
      "0.05158400535583496 seconds elapsed\n",
      "0.053028106689453125 seconds elapsed\n",
      "0.049520254135131836 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 1 potted plant, 47.9ms\n",
      "Speed: 0.5ms pre-process, 47.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 potted plant, 46.8ms\n",
      "Speed: 0.5ms pre-process, 46.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 46.5ms\n",
      "Speed: 0.4ms pre-process, 46.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 47.3ms\n",
      "Speed: 0.4ms pre-process, 47.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.051820993423461914 seconds elapsed\n",
      "0.050948143005371094 seconds elapsed\n",
      "0.05034208297729492 seconds elapsed\n",
      "0.05089616775512695 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 1 person, 1 chair, 2 potted plants, 47.8ms\n",
      "Speed: 0.4ms pre-process, 47.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 3 persons, 1 chair, 1 potted plant, 1 laptop, 46.6ms\n",
      "Speed: 0.3ms pre-process, 46.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 3 persons, 1 chair, 1 potted plant, 47.9ms\n",
      "Speed: 0.4ms pre-process, 47.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 3 persons, 1 chair, 1 potted plant, 47.6ms\n",
      "Speed: 0.3ms pre-process, 47.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0518798828125 seconds elapsed\n",
      "0.050546884536743164 seconds elapsed\n",
      "0.05133509635925293 seconds elapsed\n",
      "0.051045894622802734 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 1 potted plant, 47.3ms\n",
      "Speed: 0.5ms pre-process, 47.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 potted plant, 1 remote, 47.2ms\n",
      "Speed: 0.3ms pre-process, 47.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 potted plant, 1 laptop, 1 remote, 46.1ms\n",
      "Speed: 0.5ms pre-process, 46.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 1 laptop, 1 remote, 46.5ms\n",
      "Speed: 0.3ms pre-process, 46.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.051239967346191406 seconds elapsed\n",
      "0.050908803939819336 seconds elapsed\n",
      "0.049968719482421875 seconds elapsed\n",
      "0.05046486854553223 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 1 person, 1 airplane, 1 chair, 1 potted plant, 1 laptop, 48.6ms\n",
      "Speed: 0.3ms pre-process, 48.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 1 laptop, 46.5ms\n",
      "Speed: 0.3ms pre-process, 46.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 1 laptop, 47.4ms\n",
      "Speed: 0.4ms pre-process, 47.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 1 mouse, 1 remote, 46.0ms\n",
      "Speed: 0.4ms pre-process, 46.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05246901512145996 seconds elapsed\n",
      "0.05004692077636719 seconds elapsed\n",
      "0.05141401290893555 seconds elapsed\n",
      "0.049748897552490234 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 1 person, 1 chair, 1 potted plant, 1 laptop, 1 mouse, 59.7ms\n",
      "Speed: 0.9ms pre-process, 59.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 1 laptop, 1 mouse, 48.2ms\n",
      "Speed: 0.5ms pre-process, 48.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 1 laptop, 1 mouse, 47.5ms\n",
      "Speed: 0.4ms pre-process, 47.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 1 mouse, 46.7ms\n",
      "Speed: 0.5ms pre-process, 46.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0643000602722168 seconds elapsed\n",
      "0.052783966064453125 seconds elapsed\n",
      "0.05117225646972656 seconds elapsed\n",
      "0.05035591125488281 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 1 laptop, 1 mouse, 46.4ms\n",
      "Speed: 0.4ms pre-process, 46.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 1 laptop, 46.4ms\n",
      "Speed: 0.4ms pre-process, 46.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 3 persons, 1 chair, 1 potted plant, 1 laptop, 1 mouse, 47.1ms\n",
      "Speed: 0.6ms pre-process, 47.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 1 laptop, 45.0ms\n",
      "Speed: 0.4ms pre-process, 45.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.050194740295410156 seconds elapsed\n",
      "0.05019211769104004 seconds elapsed\n",
      "0.05105113983154297 seconds elapsed\n",
      "0.04886984825134277 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 3 persons, 1 chair, 1 potted plant, 46.9ms\n",
      "Speed: 0.3ms pre-process, 46.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 3 persons, 1 chair, 1 potted plant, 48.1ms\n",
      "Speed: 0.3ms pre-process, 48.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 48.3ms\n",
      "Speed: 0.4ms pre-process, 48.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 47.3ms\n",
      "Speed: 0.4ms pre-process, 47.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.050163984298706055 seconds elapsed\n",
      "0.05197906494140625 seconds elapsed\n",
      "0.051982879638671875 seconds elapsed\n",
      "0.0512690544128418 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 1 laptop, 48.9ms\n",
      "Speed: 0.3ms pre-process, 48.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 3 persons, 1 chair, 2 potted plants, 48.2ms\n",
      "Speed: 0.5ms pre-process, 48.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 1 laptop, 47.8ms\n",
      "Speed: 0.5ms pre-process, 47.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 1 laptop, 48.0ms\n",
      "Speed: 0.5ms pre-process, 48.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05227494239807129 seconds elapsed\n",
      "0.05214881896972656 seconds elapsed\n",
      "0.051543235778808594 seconds elapsed\n",
      "0.05120205879211426 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 47.6ms\n",
      "Speed: 0.5ms pre-process, 47.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 47.8ms\n",
      "Speed: 0.4ms pre-process, 47.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 47.5ms\n",
      "Speed: 0.3ms pre-process, 47.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 47.3ms\n",
      "Speed: 0.4ms pre-process, 47.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05196213722229004 seconds elapsed\n",
      "0.05167102813720703 seconds elapsed\n",
      "0.05129599571228027 seconds elapsed\n",
      "0.05099010467529297 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 47.7ms\n",
      "Speed: 0.5ms pre-process, 47.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 bottle, 1 chair, 1 potted plant, 1 laptop, 48.1ms\n",
      "Speed: 0.3ms pre-process, 48.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 45.9ms\n",
      "Speed: 0.4ms pre-process, 45.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.051638126373291016 seconds elapsed\n",
      "0.05203700065612793 seconds elapsed\n",
      "Bottle Found!\n",
      "0.049922943115234375 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 1 laptop, 47.2ms\n",
      "Speed: 0.4ms pre-process, 47.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 1 laptop, 65.5ms\n",
      "Speed: 0.4ms pre-process, 65.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 2 laptops, 48.9ms\n",
      "Speed: 0.5ms pre-process, 48.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.051043033599853516 seconds elapsed\n",
      "0.06929898262023926 seconds elapsed\n",
      "0.05337190628051758 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 1 person, 1 chair, 1 potted plant, 1 laptop, 48.1ms\n",
      "Speed: 0.3ms pre-process, 48.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 1 laptop, 48.4ms\n",
      "Speed: 0.4ms pre-process, 48.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 2 chairs, 1 potted plant, 1 laptop, 46.7ms\n",
      "Speed: 0.4ms pre-process, 46.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 1 laptop, 46.0ms\n",
      "Speed: 0.4ms pre-process, 46.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05193018913269043 seconds elapsed\n",
      "0.05238485336303711 seconds elapsed\n",
      "0.05088162422180176 seconds elapsed\n",
      "0.05004692077636719 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 1 cup, 1 chair, 1 potted plant, 1 laptop, 47.6ms\n",
      "Speed: 0.4ms pre-process, 47.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 1 laptop, 47.7ms\n",
      "Speed: 0.4ms pre-process, 47.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 3 chairs, 1 potted plant, 1 laptop, 48.4ms\n",
      "Speed: 0.5ms pre-process, 48.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 cup, 1 chair, 1 potted plant, 47.1ms\n",
      "Speed: 0.4ms pre-process, 47.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05142617225646973 seconds elapsed\n",
      "0.051249027252197266 seconds elapsed\n",
      "0.052516937255859375 seconds elapsed\n",
      "0.05094599723815918 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 1 cup, 1 chair, 1 potted plant, 48.7ms\n",
      "Speed: 0.4ms pre-process, 48.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 cup, 1 chair, 1 potted plant, 46.8ms\n",
      "Speed: 0.4ms pre-process, 46.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 cup, 1 chair, 1 potted plant, 49.7ms\n",
      "Speed: 0.5ms pre-process, 49.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 46.3ms\n",
      "Speed: 0.5ms pre-process, 46.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05275297164916992 seconds elapsed\n",
      "0.05078005790710449 seconds elapsed\n",
      "0.053952932357788086 seconds elapsed\n",
      "0.05031299591064453 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 46.2ms\n",
      "Speed: 0.4ms pre-process, 46.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 2 laptops, 46.5ms\n",
      "Speed: 0.4ms pre-process, 46.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 1 laptop, 47.4ms\n",
      "Speed: 0.3ms pre-process, 47.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 46.7ms\n",
      "Speed: 0.4ms pre-process, 46.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04965400695800781 seconds elapsed\n",
      "0.05055999755859375 seconds elapsed\n",
      "0.051130056381225586 seconds elapsed\n",
      "0.050390005111694336 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 1 person, 1 chair, 1 potted plant, 2 laptops, 46.4ms\n",
      "Speed: 0.5ms pre-process, 46.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 2 laptops, 48.2ms\n",
      "Speed: 0.3ms pre-process, 48.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 2 laptops, 47.8ms\n",
      "Speed: 0.4ms pre-process, 47.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 2 laptops, 46.4ms\n",
      "Speed: 0.5ms pre-process, 46.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05091404914855957 seconds elapsed\n",
      "0.05170011520385742 seconds elapsed\n",
      "0.05136609077453613 seconds elapsed\n",
      "0.0502619743347168 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 1 laptop, 47.4ms\n",
      "Speed: 0.4ms pre-process, 47.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 1 laptop, 51.7ms\n",
      "Speed: 0.4ms pre-process, 51.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 2 laptops, 49.4ms\n",
      "Speed: 0.5ms pre-process, 49.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 47.0ms\n",
      "Speed: 0.5ms pre-process, 47.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.051362037658691406 seconds elapsed\n",
      "0.056108951568603516 seconds elapsed\n",
      "0.054611921310424805 seconds elapsed\n",
      "0.05054807662963867 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 1 laptop, 47.8ms\n",
      "Speed: 0.3ms pre-process, 47.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 1 laptop, 1 mouse, 47.2ms\n",
      "Speed: 0.5ms pre-process, 47.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 1 laptop, 46.7ms\n",
      "Speed: 0.3ms pre-process, 46.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 1 laptop, 47.0ms\n",
      "Speed: 0.4ms pre-process, 47.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0513150691986084 seconds elapsed\n",
      "0.05152106285095215 seconds elapsed\n",
      "0.05037093162536621 seconds elapsed\n",
      "0.05068802833557129 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 1 laptop, 45.6ms\n",
      "Speed: 0.4ms pre-process, 45.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 47.8ms\n",
      "Speed: 0.4ms pre-process, 47.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 52.1ms\n",
      "Speed: 0.4ms pre-process, 52.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 48.4ms\n",
      "Speed: 0.5ms pre-process, 48.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04903912544250488 seconds elapsed\n",
      "0.051872968673706055 seconds elapsed\n",
      "0.056772708892822266 seconds elapsed\n",
      "0.05255007743835449 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 47.8ms\n",
      "Speed: 0.4ms pre-process, 47.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 46.6ms\n",
      "Speed: 0.4ms pre-process, 46.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 46.6ms\n",
      "Speed: 0.4ms pre-process, 46.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 47.8ms\n",
      "Speed: 0.4ms pre-process, 47.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0514371395111084 seconds elapsed\n",
      "0.05054593086242676 seconds elapsed\n",
      "0.05059504508972168 seconds elapsed\n",
      "0.052073001861572266 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 1 laptop, 47.4ms\n",
      "Speed: 0.4ms pre-process, 47.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 2 potted plants, 46.3ms\n",
      "Speed: 0.3ms pre-process, 46.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 2 chairs, 2 potted plants, 46.6ms\n",
      "Speed: 0.3ms pre-process, 46.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 3 persons, 2 chairs, 2 potted plants, 47.2ms\n",
      "Speed: 0.3ms pre-process, 47.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.050959110260009766 seconds elapsed\n",
      "0.05042099952697754 seconds elapsed\n",
      "0.05036592483520508 seconds elapsed\n",
      "0.05150198936462402 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 3 persons, 1 chair, 2 potted plants, 47.2ms\n",
      "Speed: 0.4ms pre-process, 47.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 3 persons, 1 chair, 2 potted plants, 46.9ms\n",
      "Speed: 0.4ms pre-process, 46.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 45.9ms\n",
      "Speed: 0.4ms pre-process, 45.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 48.4ms\n",
      "Speed: 0.5ms pre-process, 48.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05109095573425293 seconds elapsed\n",
      "0.050901174545288086 seconds elapsed\n",
      "0.049498796463012695 seconds elapsed\n",
      "0.0522158145904541 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 47.2ms\n",
      "Speed: 0.3ms pre-process, 47.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 45.5ms\n",
      "Speed: 0.4ms pre-process, 45.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 1 laptop, 59.7ms\n",
      "Speed: 1.1ms pre-process, 59.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 2 potted plants, 1 laptop, 46.9ms\n",
      "Speed: 0.6ms pre-process, 46.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0509037971496582 seconds elapsed\n",
      "0.04919791221618652 seconds elapsed\n",
      "0.06410908699035645 seconds elapsed\n",
      "0.05115699768066406 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 2 persons, 1 chair, 2 potted plants, 46.0ms\n",
      "Speed: 0.4ms pre-process, 46.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 47.4ms\n",
      "Speed: 0.4ms pre-process, 47.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 bottle, 1 cup, 1 chair, 2 potted plants, 47.6ms\n",
      "Speed: 0.4ms pre-process, 47.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 bottle, 1 cup, 1 chair, 1 potted plant, 1 laptop, 45.2ms\n",
      "Speed: 0.3ms pre-process, 45.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04969024658203125 seconds elapsed\n",
      "0.05115509033203125 seconds elapsed\n",
      "0.05190420150756836 seconds elapsed\n",
      "Bottle Found!\n",
      "0.04932689666748047 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 1 cup, 1 chair, 2 potted plants, 1 laptop, 47.1ms\n",
      "Speed: 0.5ms pre-process, 47.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 bottle, 1 cup, 1 chair, 2 potted plants, 1 tv, 46.9ms\n",
      "Speed: 0.5ms pre-process, 46.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 cup, 1 chair, 2 potted plants, 1 laptop, 47.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottle Found!\n",
      "0.05112600326538086 seconds elapsed\n",
      "0.05074501037597656 seconds elapsed\n",
      "Bottle Found!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 0.5ms pre-process, 47.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 cup, 1 chair, 2 potted plants, 1 laptop, 45.9ms\n",
      "Speed: 0.3ms pre-process, 45.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 cup, 1 chair, 2 potted plants, 47.7ms\n",
      "Speed: 0.5ms pre-process, 47.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 2 potted plants, 47.1ms\n",
      "Speed: 0.4ms pre-process, 47.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.051213741302490234 seconds elapsed\n",
      "0.049757957458496094 seconds elapsed\n",
      "0.05163002014160156 seconds elapsed\n",
      "0.050688982009887695 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 1 chair, 2 potted plants, 1 laptop, 47.2ms\n",
      "Speed: 0.4ms pre-process, 47.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 46.6ms\n",
      "Speed: 0.4ms pre-process, 46.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 cup, 1 chair, 1 potted plant, 2 laptops, 47.7ms\n",
      "Speed: 0.3ms pre-process, 47.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 cup, 1 chair, 1 potted plant, 2 laptops, 45.8ms\n",
      "Speed: 0.3ms pre-process, 45.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.051605224609375 seconds elapsed\n",
      "0.049944162368774414 seconds elapsed\n",
      "0.05124402046203613 seconds elapsed\n",
      "0.0497431755065918 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 1 person, 1 cup, 1 chair, 1 potted plant, 1 laptop, 48.4ms\n",
      "Speed: 0.3ms pre-process, 48.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 1 laptop, 46.2ms\n",
      "Speed: 0.4ms pre-process, 46.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 cup, 1 chair, 1 potted plant, 48.9ms\n",
      "Speed: 0.5ms pre-process, 48.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 cup, 1 chair, 1 potted plant, 1 laptop, 48.5ms\n",
      "Speed: 0.3ms pre-process, 48.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0520482063293457 seconds elapsed\n",
      "0.0499269962310791 seconds elapsed\n",
      "0.05256295204162598 seconds elapsed\n",
      "0.05239510536193848 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 1 cup, 1 chair, 2 potted plants, 1 laptop, 50.4ms\n",
      "Speed: 0.3ms pre-process, 50.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 cup, 1 chair, 2 potted plants, 1 laptop, 46.0ms\n",
      "Speed: 0.5ms pre-process, 46.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 2 potted plants, 1 laptop, 53.1ms\n",
      "Speed: 0.4ms pre-process, 53.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 2 potted plants, 1 laptop, 51.7ms\n",
      "Speed: 0.9ms pre-process, 51.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.054197072982788086 seconds elapsed\n",
      "0.049726009368896484 seconds elapsed\n",
      "0.05757784843444824 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 2 persons, 1 cup, 1 chair, 2 potted plants, 1 laptop, 48.0ms\n",
      "Speed: 0.4ms pre-process, 48.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 cup, 1 chair, 2 potted plants, 47.8ms\n",
      "Speed: 0.4ms pre-process, 47.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 cup, 1 chair, 1 potted plant, 47.6ms\n",
      "Speed: 0.3ms pre-process, 47.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05640101432800293 seconds elapsed\n",
      "0.05197405815124512 seconds elapsed\n",
      "0.051400184631347656 seconds elapsed\n",
      "0.05137777328491211 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 2 persons, 1 chair, 2 potted plants, 1 laptop, 48.1ms\n",
      "Speed: 0.5ms pre-process, 48.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 2 potted plants, 48.6ms\n",
      "Speed: 0.3ms pre-process, 48.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 1 laptop, 47.0ms\n",
      "Speed: 0.4ms pre-process, 47.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 1 laptop, 48.1ms\n",
      "Speed: 0.4ms pre-process, 48.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0524749755859375 seconds elapsed\n",
      "0.05227494239807129 seconds elapsed\n",
      "0.05073714256286621 seconds elapsed\n",
      "0.05157899856567383 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 1 cup, 1 chair, 1 potted plant, 1 laptop, 48.5ms\n",
      "Speed: 0.4ms pre-process, 48.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 1 laptop, 46.9ms\n",
      "Speed: 0.4ms pre-process, 46.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 1 laptop, 47.2ms\n",
      "Speed: 0.5ms pre-process, 47.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 2 potted plants, 1 laptop, 48.6ms\n",
      "Speed: 0.4ms pre-process, 48.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05290794372558594 seconds elapsed\n",
      "0.05110979080200195 seconds elapsed\n",
      "0.051210880279541016 seconds elapsed\n",
      "0.05288982391357422 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 2 chairs, 1 potted plant, 1 laptop, 46.6ms\n",
      "Speed: 0.5ms pre-process, 46.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 2 laptops, 1 mouse, 45.8ms\n",
      "Speed: 0.6ms pre-process, 45.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 2 laptops, 1 mouse, 45.0ms\n",
      "Speed: 0.4ms pre-process, 45.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 3 persons, 1 chair, 1 potted plant, 1 laptop, 46.9ms\n",
      "Speed: 0.4ms pre-process, 46.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.050740957260131836 seconds elapsed\n",
      "0.0504000186920166 seconds elapsed\n",
      "0.04870200157165527 seconds elapsed\n",
      "0.050649166107177734 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 1 person, 1 chair, 1 potted plant, 1 laptop, 48.1ms\n",
      "Speed: 0.4ms pre-process, 48.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 1 laptop, 46.9ms\n",
      "Speed: 0.4ms pre-process, 46.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 1 laptop, 46.5ms\n",
      "Speed: 0.4ms pre-process, 46.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 47.2ms\n",
      "Speed: 0.4ms pre-process, 47.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05198311805725098 seconds elapsed\n",
      "0.05131983757019043 seconds elapsed\n",
      "0.05036807060241699 seconds elapsed\n",
      "0.05109810829162598 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 47.2ms\n",
      "Speed: 0.3ms pre-process, 47.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 52.7ms\n",
      "Speed: 0.3ms pre-process, 52.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 laptop, 51.4ms\n",
      "Speed: 1.0ms pre-process, 51.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05054903030395508 seconds elapsed\n",
      "0.05704998970031738 seconds elapsed\n",
      "0.056485891342163086 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 1 person, 1 chair, 1 laptop, 48.5ms\n",
      "Speed: 0.4ms pre-process, 48.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 laptop, 48.4ms\n",
      "Speed: 0.6ms pre-process, 48.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 1 laptop, 48.3ms\n",
      "Speed: 0.5ms pre-process, 48.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 1 laptop, 48.5ms\n",
      "Speed: 0.4ms pre-process, 48.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05245518684387207 seconds elapsed\n",
      "0.052412986755371094 seconds elapsed\n",
      "0.05215311050415039 seconds elapsed\n",
      "0.0526280403137207 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 1 laptop, 47.0ms\n",
      "Speed: 0.4ms pre-process, 47.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 train, 1 chair, 1 potted plant, 1 laptop, 47.0ms\n",
      "Speed: 0.3ms pre-process, 47.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 train, 1 chair, 1 potted plant, 1 laptop, 47.1ms\n",
      "Speed: 0.4ms pre-process, 47.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 train, 1 chair, 1 potted plant, 1 laptop, 47.5ms\n",
      "Speed: 0.4ms pre-process, 47.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.050707340240478516 seconds elapsed\n",
      "0.05067586898803711 seconds elapsed\n",
      "0.050736188888549805 seconds elapsed\n",
      "0.05099892616271973 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 1 train, 1 chair, 1 potted plant, 1 laptop, 47.4ms\n",
      "Speed: 0.5ms pre-process, 47.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 train, 1 chair, 1 potted plant, 1 laptop, 49.6ms\n",
      "Speed: 0.4ms pre-process, 49.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 1 laptop, 48.9ms\n",
      "Speed: 0.5ms pre-process, 48.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 1 laptop, 47.8ms\n",
      "Speed: 0.4ms pre-process, 47.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05132484436035156 seconds elapsed\n",
      "0.05342221260070801 seconds elapsed\n",
      "0.05271792411804199 seconds elapsed\n",
      "0.05142998695373535 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 1 train, 1 suitcase, 1 chair, 1 potted plant, 47.9ms\n",
      "Speed: 0.4ms pre-process, 47.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 train, 1 suitcase, 1 chair, 1 potted plant, 46.9ms\n",
      "Speed: 0.4ms pre-process, 46.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 train, 1 chair, 1 potted plant, 47.6ms\n",
      "Speed: 0.3ms pre-process, 47.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 train, 1 chair, 1 potted plant, 45.9ms\n",
      "Speed: 0.4ms pre-process, 45.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0517730712890625 seconds elapsed\n",
      "0.05069899559020996 seconds elapsed\n",
      "0.051251888275146484 seconds elapsed\n",
      "0.04993033409118652 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 1 train, 1 chair, 1 potted plant, 49.0ms\n",
      "Speed: 0.3ms pre-process, 49.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 train, 1 chair, 1 potted plant, 1 laptop, 46.2ms\n",
      "Speed: 0.5ms pre-process, 46.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 train, 1 chair, 1 potted plant, 1 laptop, 47.4ms\n",
      "Speed: 0.4ms pre-process, 47.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 47.9ms\n",
      "Speed: 0.4ms pre-process, 47.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05283403396606445 seconds elapsed\n",
      "0.05032658576965332 seconds elapsed\n",
      "0.05106806755065918 seconds elapsed\n",
      "0.051589250564575195 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 47.5ms\n",
      "Speed: 0.3ms pre-process, 47.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 46.8ms\n",
      "Speed: 0.3ms pre-process, 46.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 54.3ms\n",
      "Speed: 0.3ms pre-process, 54.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05078005790710449 seconds elapsed\n",
      "0.05082297325134277 seconds elapsed\n",
      "0.058500051498413086 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 1 person, 1 chair, 1 potted plant, 51.6ms\n",
      "Speed: 0.8ms pre-process, 51.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 47.1ms\n",
      "Speed: 0.4ms pre-process, 47.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 49.7ms\n",
      "Speed: 0.4ms pre-process, 49.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 48.0ms\n",
      "Speed: 0.4ms pre-process, 48.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05678105354309082 seconds elapsed\n",
      "0.05118703842163086 seconds elapsed\n",
      "0.05338597297668457 seconds elapsed\n",
      "0.051774024963378906 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 48.5ms\n",
      "Speed: 0.5ms pre-process, 48.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 47.2ms\n",
      "Speed: 0.5ms pre-process, 47.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 47.0ms\n",
      "Speed: 0.4ms pre-process, 47.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 47.9ms\n",
      "Speed: 0.5ms pre-process, 47.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05235910415649414 seconds elapsed\n",
      "0.05091261863708496 seconds elapsed\n",
      "0.05061507225036621 seconds elapsed\n",
      "0.051715850830078125 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 1 chair, 49.0ms\n",
      "Speed: 0.4ms pre-process, 49.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 45.9ms\n",
      "Speed: 0.5ms pre-process, 45.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 49.6ms\n",
      "Speed: 0.5ms pre-process, 49.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 48.5ms\n",
      "Speed: 0.4ms pre-process, 48.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05252408981323242 seconds elapsed\n",
      "0.04986000061035156 seconds elapsed\n",
      "0.05354189872741699 seconds elapsed\n",
      "0.05281519889831543 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 1 chair, 50.8ms\n",
      "Speed: 0.4ms pre-process, 50.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 49.3ms\n",
      "Speed: 0.5ms pre-process, 49.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 48.1ms\n",
      "Speed: 0.5ms pre-process, 48.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 47.9ms\n",
      "Speed: 0.5ms pre-process, 47.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.054296016693115234 seconds elapsed\n",
      "0.05314993858337402 seconds elapsed\n",
      "0.052374839782714844 seconds elapsed\n",
      "0.052191972732543945 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 49.0ms\n",
      "Speed: 0.5ms pre-process, 49.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 48.3ms\n",
      "Speed: 0.5ms pre-process, 48.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 3 persons, 1 chair, 1 potted plant, 48.5ms\n",
      "Speed: 0.4ms pre-process, 48.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 46.6ms\n",
      "Speed: 0.4ms pre-process, 46.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.052622079849243164 seconds elapsed\n",
      "0.051850080490112305 seconds elapsed\n",
      "0.05213308334350586 seconds elapsed\n",
      "0.05013608932495117 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 3 persons, 1 chair, 1 potted plant, 47.1ms\n",
      "Speed: 0.4ms pre-process, 47.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 48.6ms\n",
      "Speed: 0.4ms pre-process, 48.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 3 persons, 1 chair, 1 potted plant, 59.6ms\n",
      "Speed: 0.4ms pre-process, 59.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05109214782714844 seconds elapsed\n",
      "0.052021026611328125 seconds elapsed\n",
      "0.06429290771484375 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 1 laptop, 50.0ms\n",
      "Speed: 0.6ms pre-process, 50.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 1 laptop, 47.9ms\n",
      "Speed: 0.5ms pre-process, 47.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 3 persons, 1 chair, 1 potted plant, 1 laptop, 48.3ms\n",
      "Speed: 0.3ms pre-process, 48.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 3 persons, 1 chair, 1 potted plant, 46.5ms\n",
      "Speed: 0.3ms pre-process, 46.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05448603630065918 seconds elapsed\n",
      "0.052420854568481445 seconds elapsed\n",
      "0.05194592475891113 seconds elapsed\n",
      "0.05035710334777832 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 3 persons, 1 chair, 1 potted plant, 48.0ms\n",
      "Speed: 0.3ms pre-process, 48.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 3 persons, 1 chair, 1 potted plant, 46.2ms\n",
      "Speed: 0.3ms pre-process, 46.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 3 persons, 1 chair, 1 potted plant, 1 laptop, 48.7ms\n",
      "Speed: 0.5ms pre-process, 48.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 3 persons, 1 chair, 1 potted plant, 1 laptop, 48.1ms\n",
      "Speed: 0.3ms pre-process, 48.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05201411247253418 seconds elapsed\n",
      "0.04992175102233887 seconds elapsed\n",
      "0.0522921085357666 seconds elapsed\n",
      "0.052247047424316406 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 3 persons, 1 chair, 1 potted plant, 46.8ms\n",
      "Speed: 0.3ms pre-process, 46.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 3 persons, 1 chair, 1 potted plant, 47.7ms\n",
      "Speed: 0.5ms pre-process, 47.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 1 laptop, 47.1ms\n",
      "Speed: 0.3ms pre-process, 47.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 1 laptop, 48.2ms\n",
      "Speed: 0.4ms pre-process, 48.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05026888847351074 seconds elapsed\n",
      "0.0515897274017334 seconds elapsed\n",
      "0.051354169845581055 seconds elapsed\n",
      "0.05199313163757324 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 2 persons, 1 train, 1 chair, 1 potted plant, 1 laptop, 47.8ms\n",
      "Speed: 0.4ms pre-process, 47.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 train, 1 chair, 1 potted plant, 47.0ms\n",
      "Speed: 0.4ms pre-process, 47.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 47.9ms\n",
      "Speed: 0.4ms pre-process, 47.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 1 remote, 48.7ms\n",
      "Speed: 0.3ms pre-process, 48.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05178189277648926 seconds elapsed\n",
      "0.050840139389038086 seconds elapsed\n",
      "0.05194401741027832 seconds elapsed\n",
      "0.05258584022521973 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 49.2ms\n",
      "Speed: 0.3ms pre-process, 49.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 3 persons, 1 chair, 1 potted plant, 48.1ms\n",
      "Speed: 0.3ms pre-process, 48.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 1 laptop, 1 remote, 49.0ms\n",
      "Speed: 0.5ms pre-process, 49.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 1 laptop, 1 remote, 48.7ms\n",
      "Speed: 0.4ms pre-process, 48.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05307435989379883 seconds elapsed\n",
      "0.05150294303894043 seconds elapsed\n",
      "0.052516937255859375 seconds elapsed\n",
      "0.05254507064819336 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 1 cat, 1 chair, 1 potted plant, 48.7ms\n",
      "Speed: 0.5ms pre-process, 48.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 train, 1 cup, 1 chair, 1 potted plant, 1 laptop, 58.6ms\n",
      "Speed: 0.3ms pre-process, 58.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "[h264 @ 0x136851000] left block unavailable for requested intra4x4 mode -1\n",
      "[h264 @ 0x136851000] error while decoding MB 0 40, bytestream 1324\n",
      "0: 448x640 1 person, 1 train, 1 chair, 1 potted plant, 53.4ms\n",
      "Speed: 0.5ms pre-process, 53.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05278897285461426 seconds elapsed\n",
      "0.06284213066101074 seconds elapsed\n",
      "0.057394981384277344 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 1 person, 1 train, 1 chair, 1 potted plant, 47.5ms\n",
      "Speed: 0.4ms pre-process, 47.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 train, 1 chair, 1 potted plant, 49.3ms\n",
      "Speed: 0.3ms pre-process, 49.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 train, 1 chair, 1 potted plant, 49.6ms\n",
      "Speed: 0.4ms pre-process, 49.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 48.5ms\n",
      "Speed: 0.5ms pre-process, 48.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05138206481933594 seconds elapsed\n",
      "0.052684783935546875 seconds elapsed\n",
      "0.05381917953491211 seconds elapsed\n",
      "0.05261087417602539 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 51.1ms\n",
      "Speed: 0.4ms pre-process, 51.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 48.0ms\n",
      "Speed: 0.4ms pre-process, 48.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 47.8ms\n",
      "Speed: 0.4ms pre-process, 47.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 50.1ms\n",
      "Speed: 0.4ms pre-process, 50.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.055203914642333984 seconds elapsed\n",
      "0.051570892333984375 seconds elapsed\n",
      "0.05225229263305664 seconds elapsed\n",
      "0.05406308174133301 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 49.9ms\n",
      "Speed: 0.3ms pre-process, 49.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 48.9ms\n",
      "Speed: 0.5ms pre-process, 48.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 49.3ms\n",
      "Speed: 0.4ms pre-process, 49.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 48.7ms\n",
      "Speed: 0.4ms pre-process, 48.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05389976501464844 seconds elapsed\n",
      "0.05305600166320801 seconds elapsed\n",
      "0.05310988426208496 seconds elapsed\n",
      "0.0531308650970459 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 49.7ms\n",
      "Speed: 0.4ms pre-process, 49.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 49.1ms\n",
      "Speed: 0.4ms pre-process, 49.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 1 laptop, 47.6ms\n",
      "Speed: 0.6ms pre-process, 47.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 49.0ms\n",
      "Speed: 0.4ms pre-process, 49.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.053540945053100586 seconds elapsed\n",
      "0.05282306671142578 seconds elapsed\n",
      "0.05149483680725098 seconds elapsed\n",
      "0.05319714546203613 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 1 laptop, 50.3ms\n",
      "Speed: 0.4ms pre-process, 50.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 49.7ms\n",
      "Speed: 0.3ms pre-process, 49.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 chair, 1 potted plant, 51.2ms\n",
      "Speed: 0.4ms pre-process, 51.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05422687530517578 seconds elapsed\n",
      "0.05371689796447754 seconds elapsed\n",
      "0.055303335189819336 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 1 person, 1 chair, 1 potted plant, 63.6ms\n",
      "Speed: 0.4ms pre-process, 63.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 54.1ms\n",
      "Speed: 0.4ms pre-process, 54.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 53.8ms\n",
      "Speed: 0.5ms pre-process, 53.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06740570068359375 seconds elapsed\n",
      "0.05825996398925781 seconds elapsed\n",
      "0.05795097351074219 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 1 person, 1 chair, 1 potted plant, 49.0ms\n",
      "Speed: 0.5ms pre-process, 49.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 train, 1 chair, 1 potted plant, 46.0ms\n",
      "Speed: 0.4ms pre-process, 46.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 train, 1 chair, 1 potted plant, 48.6ms\n",
      "Speed: 0.5ms pre-process, 48.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 48.6ms\n",
      "Speed: 0.3ms pre-process, 48.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05310392379760742 seconds elapsed\n",
      "0.050016164779663086 seconds elapsed\n",
      "0.05275297164916992 seconds elapsed\n",
      "0.05244898796081543 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 47.6ms\n",
      "Speed: 0.5ms pre-process, 47.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 3 persons, 1 chair, 1 potted plant, 48.1ms\n",
      "Speed: 0.5ms pre-process, 48.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 49.3ms\n",
      "Speed: 0.4ms pre-process, 49.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 48.3ms\n",
      "Speed: 0.5ms pre-process, 48.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05171918869018555 seconds elapsed\n",
      "0.05234408378601074 seconds elapsed\n",
      "0.05304884910583496 seconds elapsed\n",
      "0.052052974700927734 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 2 persons, 1 potted plant, 48.2ms\n",
      "Speed: 0.3ms pre-process, 48.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 potted plant, 46.8ms\n",
      "Speed: 0.4ms pre-process, 46.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 potted plant, 48.4ms\n",
      "Speed: 0.4ms pre-process, 48.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 potted plant, 48.5ms\n",
      "Speed: 0.3ms pre-process, 48.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05178499221801758 seconds elapsed\n",
      "0.05054116249084473 seconds elapsed\n",
      "0.05202937126159668 seconds elapsed\n",
      "0.05199265480041504 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 48.2ms\n",
      "Speed: 0.3ms pre-process, 48.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 46.6ms\n",
      "Speed: 0.4ms pre-process, 46.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 chair, 1 potted plant, 48.0ms\n",
      "Speed: 0.3ms pre-process, 48.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 47.9ms\n",
      "Speed: 0.5ms pre-process, 47.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05154681205749512 seconds elapsed\n",
      "0.04978299140930176 seconds elapsed\n",
      "0.05205893516540527 seconds elapsed\n",
      "0.051407814025878906 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 47.5ms\n",
      "Speed: 0.4ms pre-process, 47.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 48.6ms\n",
      "Speed: 0.4ms pre-process, 48.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 48.9ms\n",
      "Speed: 0.5ms pre-process, 48.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 50.4ms\n",
      "Speed: 0.4ms pre-process, 50.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05101299285888672 seconds elapsed\n",
      "0.05254697799682617 seconds elapsed\n",
      "0.05236506462097168 seconds elapsed\n",
      "0.05405783653259277 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 2 persons, 48.1ms\n",
      "Speed: 0.3ms pre-process, 48.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 47.8ms\n",
      "Speed: 0.3ms pre-process, 47.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 potted plant, 60.9ms\n",
      "Speed: 0.4ms pre-process, 60.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "[h264 @ 0x11702ae00] error while decoding MB 17 21, bytestream -6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05138111114501953 seconds elapsed\n",
      "0.051216840744018555 seconds elapsed\n",
      "0.0645749568939209 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 1 person, 1 potted plant, 46.8ms\n",
      "Speed: 0.6ms pre-process, 46.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 bottle, 1 potted plant, 46.1ms\n",
      "Speed: 0.5ms pre-process, 46.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 train, 45.9ms\n",
      "Speed: 0.4ms pre-process, 45.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05062079429626465 seconds elapsed\n",
      "0.04994034767150879 seconds elapsed\n",
      "Bottle Found!\n",
      "0.05021166801452637 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 1 person, 1 potted plant, 46.9ms\n",
      "Speed: 0.4ms pre-process, 46.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 potted plant, 49.3ms\n",
      "Speed: 0.4ms pre-process, 49.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 train, 1 potted plant, 47.8ms\n",
      "Speed: 0.4ms pre-process, 47.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 train, 1 potted plant, 47.8ms\n",
      "Speed: 0.4ms pre-process, 47.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05138587951660156 seconds elapsed\n",
      "0.052854061126708984 seconds elapsed\n",
      "0.05207204818725586 seconds elapsed\n",
      "0.05195498466491699 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 train, 1 potted plant, 48.8ms\n",
      "Speed: 0.4ms pre-process, 48.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 potted plant, 58.3ms\n",
      "Speed: 0.6ms pre-process, 58.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 2 persons, 1 car, 1 train, 1 potted plant, 52.0ms\n",
      "Speed: 0.4ms pre-process, 52.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05254006385803223 seconds elapsed\n",
      "0.06318998336791992 seconds elapsed\n",
      "0.05590081214904785 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 2 persons, 2 cars, 1 potted plant, 47.3ms\n",
      "Speed: 0.4ms pre-process, 47.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 car, 1 potted plant, 1 tv, 50.1ms\n",
      "Speed: 0.3ms pre-process, 50.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 car, 1 potted plant, 47.9ms\n",
      "Speed: 0.5ms pre-process, 47.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "[h264 @ 0x11702ae00] left block unavailable for requested intra mode\n",
      "[h264 @ 0x11702ae00] error while decoding MB 0 36, bytestream 1887\n",
      "\n",
      "0: 448x640 1 person, 1 car, 1 train, 1 potted plant, 1 tv, 47.7ms\n",
      "Speed: 0.5ms pre-process, 47.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05120587348937988 seconds elapsed\n",
      "0.054971933364868164 seconds elapsed\n",
      "0.05172991752624512 seconds elapsed\n",
      "0.0520482063293457 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 1 car, 1 potted plant, 1 tv, 51.0ms\n",
      "Speed: 0.4ms pre-process, 51.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 car, 1 potted plant, 1 tv, 48.7ms\n",
      "Speed: 0.3ms pre-process, 48.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 car, 1 potted plant, 1 tv, 47.7ms\n",
      "Speed: 0.4ms pre-process, 47.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 car, 1 potted plant, 1 tv, 47.2ms\n",
      "Speed: 0.5ms pre-process, 47.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0549168586730957 seconds elapsed\n",
      "0.052538156509399414 seconds elapsed\n",
      "0.052073001861572266 seconds elapsed\n",
      "0.05161571502685547 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 2 cars, 1 potted plant, 1 tv, 48.9ms\n",
      "Speed: 0.4ms pre-process, 48.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 car, 1 potted plant, 49.2ms\n",
      "Speed: 0.4ms pre-process, 49.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 car, 1 potted plant, 1 tv, 49.6ms\n",
      "Speed: 0.4ms pre-process, 49.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05294299125671387 seconds elapsed\n",
      "0.05287599563598633 seconds elapsed\n",
      "0.053791046142578125 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 1 car, 1 train, 1 potted plant, 64.4ms\n",
      "Speed: 0.7ms pre-process, 64.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 car, 1 train, 1 potted plant, 47.1ms\n",
      "Speed: 0.5ms pre-process, 47.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 car, 1 train, 1 potted plant, 52.0ms\n",
      "Speed: 0.3ms pre-process, 52.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 train, 1 potted plant, 48.5ms\n",
      "Speed: 0.4ms pre-process, 48.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06956124305725098 seconds elapsed\n",
      "0.05135703086853027 seconds elapsed\n",
      "0.05574202537536621 seconds elapsed\n",
      "0.05270504951477051 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 1 train, 1 potted plant, 49.0ms\n",
      "Speed: 0.5ms pre-process, 49.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 car, 1 potted plant, 49.9ms\n",
      "Speed: 0.4ms pre-process, 49.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 car, 1 potted plant, 49.6ms\n",
      "Speed: 0.4ms pre-process, 49.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 car, 1 potted plant, 47.3ms\n",
      "Speed: 0.5ms pre-process, 47.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05245089530944824 seconds elapsed\n",
      "0.054656028747558594 seconds elapsed\n",
      "0.05371522903442383 seconds elapsed\n",
      "0.05182814598083496 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 1 car, 1 potted plant, 49.4ms\n",
      "Speed: 0.6ms pre-process, 49.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 car, 1 potted plant, 47.0ms\n",
      "Speed: 0.4ms pre-process, 47.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 car, 1 potted plant, 50.1ms\n",
      "Speed: 0.5ms pre-process, 50.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 car, 1 potted plant, 48.3ms\n",
      "Speed: 0.3ms pre-process, 48.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05347299575805664 seconds elapsed\n",
      "0.05127382278442383 seconds elapsed\n",
      "0.05434393882751465 seconds elapsed\n",
      "0.052024126052856445 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 1 car, 1 potted plant, 48.2ms\n",
      "Speed: 0.5ms pre-process, 48.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 car, 1 potted plant, 48.3ms\n",
      "Speed: 0.4ms pre-process, 48.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 car, 1 potted plant, 47.9ms\n",
      "Speed: 0.4ms pre-process, 47.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 train, 1 potted plant, 48.3ms\n",
      "Speed: 0.3ms pre-process, 48.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.051733970642089844 seconds elapsed\n",
      "0.05174612998962402 seconds elapsed\n",
      "0.05205035209655762 seconds elapsed\n",
      "0.05195498466491699 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 train, 1 potted plant, 47.5ms\n",
      "Speed: 0.4ms pre-process, 47.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 car, 1 train, 1 potted plant, 46.6ms\n",
      "Speed: 0.3ms pre-process, 46.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 car, 1 train, 1 potted plant, 46.4ms\n",
      "Speed: 0.4ms pre-process, 46.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 car, 1 potted plant, 48.5ms\n",
      "Speed: 0.3ms pre-process, 48.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05112195014953613 seconds elapsed\n",
      "0.05091404914855957 seconds elapsed\n",
      "0.050209999084472656 seconds elapsed\n",
      "0.05160021781921387 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 1 potted plant, 48.3ms\n",
      "Speed: 0.4ms pre-process, 48.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 car, 1 potted plant, 48.8ms\n",
      "Speed: 0.4ms pre-process, 48.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 car, 1 potted plant, 60.2ms\n",
      "Speed: 0.5ms pre-process, 60.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0525362491607666 seconds elapsed\n",
      "0.05258584022521973 seconds elapsed\n",
      "0.06552505493164062 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 448x640 1 person, 1 car, 1 potted plant, 63.6ms\n",
      "Speed: 0.7ms pre-process, 63.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 car, 1 potted plant, 51.6ms\n",
      "Speed: 0.4ms pre-process, 51.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 car, 1 potted plant, 49.6ms\n",
      "Speed: 0.4ms pre-process, 49.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 car, 1 potted plant, 47.1ms\n",
      "Speed: 0.3ms pre-process, 47.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06829595565795898 seconds elapsed\n",
      "0.056900739669799805 seconds elapsed\n",
      "0.05364394187927246 seconds elapsed\n",
      "0.05097389221191406 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 1 car, 1 potted plant, 49.2ms\n",
      "Speed: 0.4ms pre-process, 49.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 car, 1 potted plant, 47.5ms\n",
      "Speed: 0.4ms pre-process, 47.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 car, 1 couch, 1 potted plant, 50.1ms\n",
      "Speed: 0.5ms pre-process, 50.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 car, 1 potted plant, 49.6ms\n",
      "Speed: 0.5ms pre-process, 49.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05301785469055176 seconds elapsed\n",
      "0.05126190185546875 seconds elapsed\n",
      "0.05428194999694824 seconds elapsed\n",
      "0.05348515510559082 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 1 train, 1 potted plant, 48.6ms\n",
      "Speed: 0.5ms pre-process, 48.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 car, 1 potted plant, 48.0ms\n",
      "Speed: 0.4ms pre-process, 48.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 car, 1 potted plant, 48.8ms\n",
      "Speed: 0.5ms pre-process, 48.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 car, 1 potted plant, 47.7ms\n",
      "Speed: 0.4ms pre-process, 47.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05252408981323242 seconds elapsed\n",
      "0.05217409133911133 seconds elapsed\n",
      "0.05348396301269531 seconds elapsed\n",
      "0.05121016502380371 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 1 car, 1 potted plant, 47.5ms\n",
      "Speed: 0.5ms pre-process, 47.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 car, 1 potted plant, 47.0ms\n",
      "Speed: 0.5ms pre-process, 47.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 car, 1 potted plant, 49.5ms\n",
      "Speed: 0.3ms pre-process, 49.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 car, 1 potted plant, 48.3ms\n",
      "Speed: 0.4ms pre-process, 48.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05121207237243652 seconds elapsed\n",
      "0.05145716667175293 seconds elapsed\n",
      "0.05335187911987305 seconds elapsed\n",
      "0.05204606056213379 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 1 car, 1 potted plant, 48.2ms\n",
      "Speed: 0.4ms pre-process, 48.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 car, 1 potted plant, 48.0ms\n",
      "Speed: 0.4ms pre-process, 48.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 car, 1 potted plant, 48.3ms\n",
      "Speed: 0.4ms pre-process, 48.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 car, 1 potted plant, 47.5ms\n",
      "Speed: 0.3ms pre-process, 47.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05192399024963379 seconds elapsed\n",
      "0.051259756088256836 seconds elapsed\n",
      "0.0519709587097168 seconds elapsed\n",
      "0.051805973052978516 seconds elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 1 car, 1 potted plant, 48.2ms\n",
      "Speed: 0.4ms pre-process, 48.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 car, 1 potted plant, 46.4ms\n",
      "Speed: 0.3ms pre-process, 46.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05189085006713867 seconds elapsed\n",
      "0.0507657527923584 seconds elapsed\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# trk = Thread(target=track)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# trk.start()\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m track()\n",
      "Cell \u001b[0;32mIn[20], line 7\u001b[0m, in \u001b[0;36mtrack\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m img \u001b[39m=\u001b[39m drone\u001b[39m.\u001b[39mget_frame_read()\u001b[39m.\u001b[39mframe\n\u001b[1;32m      6\u001b[0m img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mresize(img, (\u001b[39m360\u001b[39m, \u001b[39m240\u001b[39m))\n\u001b[0;32m----> 7\u001b[0m top_left, bottom_right \u001b[39m=\u001b[39m get_coords(\u001b[39m\"\u001b[39;49m\u001b[39mbottle\u001b[39;49m\u001b[39m\"\u001b[39;49m, img)\n\u001b[1;32m      8\u001b[0m cv2\u001b[39m.\u001b[39mimshow(\u001b[39m\"\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m\"\u001b[39m, img)\n\u001b[1;32m      9\u001b[0m cv2\u001b[39m.\u001b[39mwaitKey(\u001b[39m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m, in \u001b[0;36mget_coords\u001b[0;34m(obj_name, img_url, verbose)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_coords\u001b[39m(obj_name, img_url, verbose\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m): \u001b[39m# obj_name must be a valid YOLO class\u001b[39;00m\n\u001b[1;32m      2\u001b[0m     start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m----> 3\u001b[0m     pred \u001b[39m=\u001b[39m model(img_url)\n\u001b[1;32m      5\u001b[0m     \u001b[39mif\u001b[39;00m verbose:\n\u001b[1;32m      6\u001b[0m         \u001b[39mprint\u001b[39m(pred)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/ultralytics/yolo/engine/model.py:71\u001b[0m, in \u001b[0;36mYOLO.__call__\u001b[0;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, source\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, stream\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 71\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(source, stream, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/ultralytics/yolo/engine/model.py:169\u001b[0m, in \u001b[0;36mYOLO.predict\u001b[0;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredictor\u001b[39m.\u001b[39margs \u001b[39m=\u001b[39m get_cfg(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredictor\u001b[39m.\u001b[39margs, overrides)\n\u001b[1;32m    168\u001b[0m is_cli \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39margv[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39myolo\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mor\u001b[39;00m sys\u001b[39m.\u001b[39margv[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39multralytics\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 169\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredictor\u001b[39m.\u001b[39mpredict_cli(source\u001b[39m=\u001b[39msource) \u001b[39mif\u001b[39;00m is_cli \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredictor(source\u001b[39m=\u001b[39;49msource, stream\u001b[39m=\u001b[39;49mstream)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/ultralytics/yolo/engine/predictor.py:113\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[0;34m(self, source, model, stream)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstream_inference(source, model)\n\u001b[1;32m    112\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 113\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstream_inference(source, model))\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/ultralytics/yolo/engine/predictor.py:168\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[0;34m(self, source, model)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[39m# Inference\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdt[\u001b[39m1\u001b[39m]:\n\u001b[0;32m--> 168\u001b[0m     preds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(im, augment\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs\u001b[39m.\u001b[39;49maugment, visualize\u001b[39m=\u001b[39;49mvisualize)\n\u001b[1;32m    170\u001b[0m \u001b[39m# postprocess\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdt[\u001b[39m2\u001b[39m]:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/ultralytics/nn/autobackend.py:292\u001b[0m, in \u001b[0;36mAutoBackend.forward\u001b[0;34m(self, im, augment, visualize)\u001b[0m\n\u001b[1;32m    289\u001b[0m     im \u001b[39m=\u001b[39m im\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m1\u001b[39m)  \u001b[39m# torch BCHW to numpy BHWC shape(1,320,192,3)\u001b[39;00m\n\u001b[1;32m    291\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpt \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnn_module:  \u001b[39m# PyTorch\u001b[39;00m\n\u001b[0;32m--> 292\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(im, augment\u001b[39m=\u001b[39maugment, visualize\u001b[39m=\u001b[39mvisualize) \u001b[39mif\u001b[39;00m augment \u001b[39mor\u001b[39;00m visualize \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(im)\n\u001b[1;32m    293\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjit:  \u001b[39m# TorchScript\u001b[39;00m\n\u001b[1;32m    294\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(im)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/ultralytics/nn/tasks.py:200\u001b[0m, in \u001b[0;36mDetectionModel.forward\u001b[0;34m(self, x, augment, profile, visualize)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mif\u001b[39;00m augment:\n\u001b[1;32m    199\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_augment(x)  \u001b[39m# augmented inference, None\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_once(x, profile, visualize)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/ultralytics/nn/tasks.py:59\u001b[0m, in \u001b[0;36mBaseModel._forward_once\u001b[0;34m(self, x, profile, visualize)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39mif\u001b[39;00m profile:\n\u001b[1;32m     58\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[0;32m---> 59\u001b[0m x \u001b[39m=\u001b[39m m(x)  \u001b[39m# run\u001b[39;00m\n\u001b[1;32m     60\u001b[0m y\u001b[39m.\u001b[39mappend(x \u001b[39mif\u001b[39;00m m\u001b[39m.\u001b[39mi \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m)  \u001b[39m# save output\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[39mif\u001b[39;00m visualize:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/ultralytics/nn/modules.py:192\u001b[0m, in \u001b[0;36mC2f.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m    191\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv1(x)\u001b[39m.\u001b[39msplit((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mc, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mc), \u001b[39m1\u001b[39m))\n\u001b[0;32m--> 192\u001b[0m     y\u001b[39m.\u001b[39;49mextend(m(y[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]) \u001b[39mfor\u001b[39;49;00m m \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mm)\n\u001b[1;32m    193\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv2(torch\u001b[39m.\u001b[39mcat(y, \u001b[39m1\u001b[39m))\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/ultralytics/nn/modules.py:192\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m    191\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv1(x)\u001b[39m.\u001b[39msplit((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mc, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mc), \u001b[39m1\u001b[39m))\n\u001b[0;32m--> 192\u001b[0m     y\u001b[39m.\u001b[39mextend(m(y[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]) \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mm)\n\u001b[1;32m    193\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv2(torch\u001b[39m.\u001b[39mcat(y, \u001b[39m1\u001b[39m))\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/ultralytics/nn/modules.py:130\u001b[0m, in \u001b[0;36mBottleneck.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m--> 130\u001b[0m     \u001b[39mreturn\u001b[39;00m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv2(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcv1(x)) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv2(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv1(x))\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/ultralytics/nn/modules.py:37\u001b[0m, in \u001b[0;36mConv.forward_fuse\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward_fuse\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> 37\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mact(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv(x))\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x11704fe00] left block unavailable for requested intra mode\n",
      "[h264 @ 0x11704fe00] error while decoding MB 0 27, bytestream 949\n",
      "[h264 @ 0x117037a00] left block unavailable for requested intra mode\n",
      "[h264 @ 0x117037a00] error while decoding MB 0 36, bytestream 1776\n",
      "[h264 @ 0x117027e00] left block unavailable for requested intra mode\n",
      "[h264 @ 0x117027e00] error while decoding MB 0 36, bytestream 1717\n",
      "[h264 @ 0x11703c800] error while decoding MB 6 38, bytestream -5\n",
      "[h264 @ 0x117027e00] left block unavailable for requested intra mode\n",
      "[h264 @ 0x117027e00] error while decoding MB 0 37, bytestream 1748\n",
      "[h264 @ 0x11702ae00] left block unavailable for requested intra mode\n",
      "[h264 @ 0x11702ae00] error while decoding MB 0 12, bytestream 2260\n",
      "[h264 @ 0x117050400] left block unavailable for requested intra mode\n",
      "[h264 @ 0x117050400] error while decoding MB 0 29, bytestream 1770\n",
      "[h264 @ 0x117027e00] left block unavailable for requested intra mode\n",
      "[h264 @ 0x117027e00] error while decoding MB 0 27, bytestream 1587\n",
      "[h264 @ 0x117037a00] error while decoding MB 8 35, bytestream -6\n",
      "[h264 @ 0x11704fe00] error while decoding MB 3 40, bytestream -6\n",
      "[h264 @ 0x11702ae00] left block unavailable for requested intra4x4 mode -1\n",
      "[h264 @ 0x11702ae00] error while decoding MB 0 37, bytestream 1515\n",
      "[h264 @ 0x11704fe00] left block unavailable for requested intra mode\n",
      "[h264 @ 0x11704fe00] error while decoding MB 0 34, bytestream 1459\n",
      "[h264 @ 0x117037a00] left block unavailable for requested intra mode\n",
      "[h264 @ 0x117037a00] error while decoding MB 0 29, bytestream 1752\n",
      "[h264 @ 0x136850a00] left block unavailable for requested intra mode\n",
      "[h264 @ 0x136850a00] error while decoding MB 0 28, bytestream 1850\n"
     ]
    }
   ],
   "source": [
    "# Test exploration-exploitation\n",
    "if 0: # Tracking thread\n",
    "    trk = Thread(target=track)\n",
    "    trk.start()\n",
    "if 1:\n",
    "    track() # track objects in observation space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Legacy Functions (1st Implementation)\n",
    "def find_corners(upper_left: tuple, length: float, width: float) -> list:\n",
    "    \"\"\"\n",
    "    Find the 4 corners of a bounding box, given the upper left corner, length, and width.\n",
    "\n",
    "    Args:\n",
    "        upper_left (tuple): Upper left coordinates of the bounding box.\n",
    "        length (float): Length of the bounding box\n",
    "        width (float): Width of the bounding box\n",
    "\n",
    "    Returns:\n",
    "        corners (list): A list containing the coordinates of the 4 corners of the bounding box.\n",
    "    \"\"\"\n",
    "    corners = []\n",
    "    \n",
    "    upper_right = (upper_left[0] + length, upper_left[1])\n",
    "    lower_left =  (upper_left[0], upper_left[1] + width)\n",
    "    lower_right = (upper_left[0] + length, upper_left[1] + width)\n",
    "    \n",
    "    corners.append(upper_left)\n",
    "    corners.append(upper_right)\n",
    "    corners.append(lower_left)\n",
    "    corners.append(lower_right)\n",
    "    \n",
    "    return corners\n",
    "    \n",
    "\n",
    "def find_center(corners: list) -> tuple:\n",
    "    \"\"\"\n",
    "    Find the center coordinates of a bounding box, given the 4 corners of the bounding box.\n",
    "\n",
    "    Args:\n",
    "        corners (list): A list containing the coordinates of the 4 corners of the bounding box.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: Coordinates of the center of the bounding box.\n",
    "    \"\"\"\n",
    "    upper_left, upper_right, lower_left, lower_right = corners\n",
    "    \n",
    "    # create diagonal using upper left and lower right\n",
    "    center_x = (upper_left[0] + upper_right[0]) / 2\n",
    "    center_y = (upper_left[1] + lower_right[1]) / 2\n",
    "    \n",
    "    return(center_x, center_y)\n",
    "\n",
    "\n",
    "def compact_exploit(drone, bbox): # prompt_template = explore_template):\n",
    "    \"\"\"\n",
    "    Legacy compact implementation of the Exploit Function: Given the bounding box of a target of interest, execute two transformations to move closer to the object\n",
    "\n",
    "    Args:\n",
    "        drone: Tello (djiteleopy) object that specifies actions to be taken on a DJI Tello drone over WiFi and offers data streaming capabilities.\n",
    "        bbox (list): A list containing the 4 corners of a bounding box.\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Translate the object to the center\n",
    "    bounding_box_center = find_center(bbox)\n",
    "    current_image = drone.get_frame_read().frame\n",
    "    height, width, channel = current_image.shape\n",
    "    frame_center = (width / 2, height / 2)\n",
    "    \n",
    "    delta_y = frame_center[1] - bounding_box_center[1]\n",
    "    delta_x = frame_center[0] - bounding_box_center[0]\n",
    "    \n",
    "    if delta_y < 0:\n",
    "        drone.move_up(abs(delta_y))\n",
    "    else:\n",
    "        drone.move_down(abs(delta_y))\n",
    "    \n",
    "    if delta_x < 0:\n",
    "        drone.move_left(abs(delta_x))\n",
    "    else:\n",
    "        drone.move_right(abs(delta_x))\n",
    "    \n",
    "    # Zoom In (move towards the object)\n",
    "    bbox_length = bbox[1][0] - bbox[0][0]\n",
    "    bbox_width = bbox[1][1] - bbox[0][1]\n",
    "    \n",
    "    while bbox_width <= 100 or bbox_length <= 100:\n",
    "        drone.move_forward(10)\n",
    "    \n",
    "    # Terminate\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Pre-Trained VQA Model\n",
    "processor = ViltProcessor.from_pretrained(\"dandelin/vilt-b32-finetuned-vqa\")\n",
    "model = ViltForQuestionAnswering.from_pretrained(\"dandelin/vilt-b32-finetuned-vqa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] tello.py - 437 - Send command: 'command'\n",
      "[WARNING] tello.py - 447 - Aborting command 'command'. Did not receive a response after 7 seconds\n",
      "[INFO] tello.py - 437 - Send command: 'command'\n",
      "[WARNING] tello.py - 447 - Aborting command 'command'. Did not receive a response after 7 seconds\n",
      "[INFO] tello.py - 437 - Send command: 'command'\n",
      "[WARNING] tello.py - 447 - Aborting command 'command'. Did not receive a response after 7 seconds\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Command 'command' was unsuccessful for 4 tries. Latest response:\t'Aborting command 'command'. Did not receive a response after 7 seconds'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m drone\u001b[39m.\u001b[39;49mconnect()\n",
      "File \u001b[0;32m~/anaconda3/envs/droneformer/lib/python3.10/site-packages/djitellopy/enforce_types.py:54\u001b[0m, in \u001b[0;36menforce_types.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m     52\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     53\u001b[0m     check_types(spec, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 54\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/droneformer/lib/python3.10/site-packages/djitellopy/tello.py:534\u001b[0m, in \u001b[0;36mTello.connect\u001b[0;34m(self, wait_for_state)\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconnect\u001b[39m(\u001b[39mself\u001b[39m, wait_for_state\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    532\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Enter SDK mode. Call this before any of the control functions.\u001b[39;00m\n\u001b[1;32m    533\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 534\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend_control_command(\u001b[39m\"\u001b[39;49m\u001b[39mcommand\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    536\u001b[0m     \u001b[39mif\u001b[39;00m wait_for_state:\n\u001b[1;32m    537\u001b[0m         REPS \u001b[39m=\u001b[39m \u001b[39m20\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/droneformer/lib/python3.10/site-packages/djitellopy/enforce_types.py:54\u001b[0m, in \u001b[0;36menforce_types.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m     52\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     53\u001b[0m     check_types(spec, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 54\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/droneformer/lib/python3.10/site-packages/djitellopy/tello.py:486\u001b[0m, in \u001b[0;36mTello.send_control_command\u001b[0;34m(self, command, timeout)\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    484\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLOGGER\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mCommand attempt #\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m failed for command: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(i, command))\n\u001b[0;32m--> 486\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraise_result_error(command, response)\n\u001b[1;32m    487\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/droneformer/lib/python3.10/site-packages/djitellopy/enforce_types.py:54\u001b[0m, in \u001b[0;36menforce_types.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m     52\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     53\u001b[0m     check_types(spec, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 54\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/droneformer/lib/python3.10/site-packages/djitellopy/tello.py:528\u001b[0m, in \u001b[0;36mTello.raise_result_error\u001b[0;34m(self, command, response)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Used to reaise an error after an unsuccessful command\u001b[39;00m\n\u001b[1;32m    525\u001b[0m \u001b[39mInternal method, you normally wouldn't call this yourself.\u001b[39;00m\n\u001b[1;32m    526\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    527\u001b[0m tries \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretry_count\n\u001b[0;32m--> 528\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCommand \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m was unsuccessful for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m tries. Latest response:\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    529\u001b[0m                 \u001b[39m.\u001b[39mformat(command, tries, response))\n",
      "\u001b[0;31mException\u001b[0m: Command 'command' was unsuccessful for 4 tries. Latest response:\t'Aborting command 'command'. Did not receive a response after 7 seconds'"
     ]
    }
   ],
   "source": [
    "# Set up the Drone\n",
    "objective = \"Find the person who is wearing a blue cap\" # initialize LLM objective prompt\n",
    "\n",
    "drone.connect() # Establish network connection\n",
    "\n",
    "take_individual_picture(drone) # take an individual picture to test imaging capabilities\n",
    "\n",
    "# Begin a thread and stream video frame by frame\n",
    "stream = Thread(target=stream_frames, args=(drone, False))\n",
    "stream.start()\n",
    "\n",
    "# Enable drone streaming and launch\n",
    "drone.streamon()\n",
    "drone.takeoff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_the_environment(drone, question):\n",
    "    \"\"\"\n",
    "    Given any image frame streamed from the drone, this function uses VQA to identify objects of interest specified by a prompt question.\n",
    "\n",
    "    Args:\n",
    "        drone: Tello (djiteleopy) object that specifies actions to be taken on a DJI Tello drone over WiFi and offers data streaming capabilities.\n",
    "        question (str): LLM objective prompt - high level task that is to be completed.\n",
    "\n",
    "    Returns:\n",
    "        str: Label of the object of interest specified by the question in the image\n",
    "    \"\"\"\n",
    "    image = drone.get_frame_read().frame\n",
    "    encoding = processor(image, question, return_tensors=\"pt\")\n",
    "    outputs = model(**encoding)\n",
    "    logits = outputs.logits\n",
    "    idx = torch.sigmoid(logits).argmax(-1).item()\n",
    "    return str(model.config.id2label[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_action_prompt(prompt_template, objective, environment_context, previous_commands, previous_context, vqa_questions):\n",
    "    \"\"\"\n",
    "    Generate a complete action prompt for the LLM given an objective, environment context, previous commands, previous context, and VQA questions.\n",
    "\n",
    "    Args:\n",
    "        prompt_template (str): LLM Prompt Template.\n",
    "        objective (str): The objective that the drone should complete.\n",
    "        environment_context (str): Environmental Context.\n",
    "        previous_commands (str): Previous commands given to the drone, converted into string form such that it can be added to the prompt.\n",
    "        previous_context (str): Previous environemal context understood by the drone.\n",
    "        vqa_questions (str): Questions for Visual Question-Answering.\n",
    "\n",
    "    Returns:\n",
    "        tuple(str, list): Prompt text and list containing stop tokens\n",
    "    \"\"\"\n",
    "    prompt = prompt_template.replace(\"$objective\", objective)\n",
    "    prompt = prompt.replace(\"$context\", environment_context)\n",
    "    prompt = prompt.replace(\"$previous_commands\", previous_commands)\n",
    "    prompt = prompt.replace(\"$previous_context\", previous_context)\n",
    "    prompt = prompt.replace(\"$vqa_questions\", vqa_questions)\n",
    "    return prompt, [\"\\n\"] # prompt and stop token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt(prompt, stop_tokens):\n",
    "    \"\"\"\n",
    "    Pass a prompt through an LLM model and return the output.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): Prompt to be passed through the LLM model.\n",
    "        stop_tokens (list): List of stop tokens for the LLM to parse through.\n",
    "\n",
    "    Returns:\n",
    "        str: LLM Prompt Response\n",
    "    \"\"\"\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",\n",
    "        prompt=prompt,\n",
    "        temperature=0.5,\n",
    "        max_tokens=1000,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        best_of=10,\n",
    "        stop=stop_tokens,\n",
    "    )\n",
    "    return response.choices[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vqa_questions(vqa_prompt_template, objective):\n",
    "    \"\"\"\n",
    "    Generate questions for VQA automatically given a prompt template and a user-specified objective.\n",
    "\n",
    "    Args:\n",
    "        vqa_prompt_template (str): Prompt template for VQA questions.\n",
    "        objective (str): User-specified objective that the drone is tasked to complete.\n",
    "\n",
    "    Returns:\n",
    "        matches (list): A list of questions that are used to query the VQA model.\n",
    "    \"\"\"\n",
    "    prompt_text = vqa_prompt_template.replace(\"$objective\", objective)\n",
    "    result = prompt(prompt_text, [\"&&&&&&\"])\n",
    "    matches = re.findall(r'@(.+?)@', result)\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Is there a person in the image?', 'Is there a blue cap in the image?']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate VQA Questions: test\n",
    "get_vqa_questions(vqa_prompt_template, objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore(drone, use_gpt=False, prompt_template=explore_template):\n",
    "    \"\"\"\n",
    "    Explore Function: Survey the room via a random though comprehensive flight path to find objects of interest as specified by the prompt.\n",
    "\n",
    "    Args:\n",
    "        drone: Tello (djiteleopy) object that specifies actions to be taken on a DJI Tello drone over WiFi and offers data streaming capabilities.\n",
    "        use_gpt (bool, optional): Whether or not to use a GPT-type LLM to parse through the prompt. Defaults to False.\n",
    "        prompt_template (str, optional): Prompt template for the specified objective. Defaults to explore_template.\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Generate Prompt Response\n",
    "    if use_gpt:\n",
    "       prompt(prompt_template)\n",
    "    else:\n",
    "        # randomly generate a number between 45 and 180\n",
    "        random_angle = r.randint(45, 180)\n",
    "        \n",
    "        # randomly generate a number between 5 and 20\n",
    "        random_distance = r.randint(5, 20)\n",
    "        action_space = [\n",
    "            (drone.move_left, random_distance),\n",
    "            (drone.move_right, random_distance),\n",
    "            (drone.rotate_clockwise, random_angle),\n",
    "            (drone.rotate_counter_clockwise, random_angle),\n",
    "            (drone.move_forward, random_distance),\n",
    "            (drone.move_back, random_distance),\n",
    "        ]\n",
    "        \n",
    "        # sample 3 actions at random\n",
    "        sampled_actions = r.sample(action_space, 3)\n",
    "        for action in sampled_actions:\n",
    "            action[0](action[1])\n",
    "            time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'explore_template' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 28\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[39mreturn\u001b[39;00m(center_x, center_y)\n\u001b[1;32m     27\u001b[0m \u001b[39m# Exploit Function: Input we have a bounding box with 4 corners (or 1 corner + length and width for a more compact representation)\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mexploit\u001b[39m(drone, bbox, use_gpt \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, prompt_template \u001b[39m=\u001b[39m explore_template):\n\u001b[1;32m     29\u001b[0m     \u001b[39mif\u001b[39;00m use_gpt:\n\u001b[1;32m     30\u001b[0m         prompt(prompt_template)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'explore_template' is not defined"
     ]
    }
   ],
   "source": [
    "# Get the 4 points of a bounding box\n",
    "def find_corners(upper_left: tuple, length: float, width: float) -> list:\n",
    "    \"\"\"\n",
    "    Find the 4 corners of a bounding box, given the upper left corner, length, and width.\n",
    "\n",
    "    Args:\n",
    "        upper_left (tuple): Upper left coordinates of the bounding box.\n",
    "        length (float): Length of the bounding box\n",
    "        width (float): Width of the bounding box\n",
    "\n",
    "    Returns:\n",
    "        corners (list): A list containing the coordinates of the 4 corners of the bounding box.\n",
    "    \"\"\"\n",
    "    corners = []\n",
    "    \n",
    "    upper_right = (upper_left[0] + length, upper_left[1])\n",
    "    lower_left =  (upper_left[0], upper_left[1] + width)\n",
    "    lower_right = (upper_left[0] + length, upper_left[1] + width)\n",
    "    \n",
    "    corners.append(upper_left)\n",
    "    corners.append(upper_right)\n",
    "    corners.append(lower_left)\n",
    "    corners.append(lower_right)\n",
    "    \n",
    "    return corners\n",
    "\n",
    "    \n",
    "# Find the center of a bounding box\n",
    "def find_center(corners: list) -> tuple:\n",
    "    \"\"\"\n",
    "    Find the center coordinates of a bounding box, given the 4 corners of the bounding box.\n",
    "\n",
    "    Args:\n",
    "        corners (list): A list containing the coordinates of the 4 corners of the bounding box.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: Coordinates of the center of the bounding box.\n",
    "    \"\"\"\n",
    "    upper_left, upper_right, lower_left, lower_right = corners\n",
    "    \n",
    "    # create diagonal using upper left and lower right\n",
    "    center_x = (upper_left[0] + upper_right[0]) / 2\n",
    "    center_y = (upper_left[1] + lower_right[1]) / 2\n",
    "    \n",
    "    return(center_x, center_y)\n",
    "\n",
    "\n",
    "# Exploit Function: Input we have a bounding box with 4 corners (or 1 corner + length and width for a more compact representation)\n",
    "def exploit(drone, bbox, use_gpt = False, prompt_template = explore_template):\n",
    "    \"\"\"\n",
    "    Legacy implementation of the Exploit Function: Given the bounding box of a target of interest, execute two transformations to move closer to the object\n",
    "\n",
    "    Args:\n",
    "        drone: Tello (djiteleopy) object that specifies actions to be taken on a DJI Tello drone over WiFi and offers data streaming capabilities.\n",
    "        bbox (list): A list containing the 4 corners of a bounding box.\n",
    "        use_gpt (bool, optional): Whether or not to use GPT prompt for control. Defaults to False.\n",
    "        prompt_template (str, optional): LLM prompt template. Defaults to explore_template.\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    if use_gpt:\n",
    "        prompt(prompt_template)\n",
    "        \n",
    "    distance_to_object = None\n",
    "    angle_to_object = None\n",
    "    height_to_object = None\n",
    "    actions = [\n",
    "        (drone.move_left, distance_to_object),\n",
    "        (drone.move_right, distance_to_object),\n",
    "        (drone.rotate_clockwise, angle_to_object),\n",
    "        (drone.rotate_counter_clockwise, angle_to_object),\n",
    "        (drone.move_forward, distance_to_object),\n",
    "        (drone.move_back, distance_to_object) \n",
    "    ]\n",
    "        \n",
    "    # Step 1: Find out whether or not the drone is facing the object\n",
    "    object_in_frame = False\n",
    "    while object_in_frame == False:\n",
    "        drone.rotate_clockwise(30)\n",
    "    \n",
    "    \n",
    "    # Step 2: Translate the object to the center\n",
    "    bounding_box_center = find_center(bbox)\n",
    "    current_image = drone.get_frame_read().frame\n",
    "    height, width, channel = current_image.shape\n",
    "    frame_center = (width / 2, height / 2)\n",
    "    \n",
    "    delta_y = frame_center[1] - bounding_box_center[1]\n",
    "    delta_x = frame_center[0] - bounding_box_center[0]\n",
    "    \n",
    "    if delta_y < 0:\n",
    "        drone.move_up(abs(delta_y))\n",
    "    else:\n",
    "        drone.move_down(abs(delta_y))\n",
    "    \n",
    "    if delta_x < 0:\n",
    "        drone.move_left(abs(delta_x))\n",
    "    else:\n",
    "        drone.move_right(abs(delta_x))\n",
    "    \n",
    "    # Step 3: Zoom In (move towards the object)\n",
    "    bbox_length = bbox[1][0] - bbox[0][0]\n",
    "    bbox_width = bbox[1][1] - bbox[0][1]\n",
    "    \n",
    "    while bbox_width <= 100 or bbox_length <= 100:\n",
    "        drone.move_forward(10)\n",
    "    \n",
    "    # Step 4: Terminate\n",
    "    return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5940fbd60f4524a89d25f69a9047e7141ce4840794657a7e6183bb38ffdcde84"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
